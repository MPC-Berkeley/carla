{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from kf_impl import EKF_CV_MODEL\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to extract training data from pickles\n",
    "def extract_data(pklfile, crop=None):\n",
    "    with open(pklfile, 'rb') as f:\n",
    "        dataset_all = pickle.load(f)\n",
    "        \n",
    "    # All the history trajectoreis (x, y, heading), with shape (batch_size, sequence_length, feature_dims)\n",
    "    history_traj_data = np.array(dataset_all['features'])[:, :, :]\n",
    "\n",
    "    # All the future trajectoreis (x, y, heading), with shape (batch_size, sequence_length, feature_dims)\n",
    "    future_traj_data = np.array(dataset_all['labels'])[:, :, :-1]\n",
    "\n",
    "    # All the goal positins and occupancy (x, y, occup), with shape (batch_size, (goal_nums * feature_dims))\n",
    "    goals_position = np.array(dataset_all['goals'])\n",
    "    goals_position = goals_position.reshape((goals_position.shape[0], goals_position.shape[1] * goals_position.shape[2]))\n",
    "\n",
    "    # All intention labels, with shape (batch_size, goal_nums)\n",
    "    goal_idx = np.array(dataset_all['labels'])[:, 0, -1]\n",
    "    # Convert to one-hot and the last one is undecided (-1)\n",
    "    one_hot_goal = to_categorical(goal_idx, num_classes=33)\n",
    "    \n",
    "    if crop is not None:\n",
    "        raise NotImplementedError(\"TODO\")\n",
    "    \n",
    "    return history_traj_data, future_traj_data, goals_position, one_hot_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_splits(pklfiles_to_process, num_pkl_folds=5):\n",
    "    # Using a suboptimal approach here:\n",
    "    # Just build a list of dictionaries, where entry_i \n",
    "    # corresponds to train split i.\n",
    "\n",
    "    train_sets = []\n",
    "    test_sets  = []\n",
    "    \n",
    "    \n",
    "    inds = np.arange(num_pkl_folds)\n",
    "    \n",
    "    for hold_out_ind in inds:\n",
    "        train_inds = np.delete(inds, hold_out_ind)\n",
    "        \n",
    "        train_set = {\"history_traj_data\" : None,\n",
    "                     \"future_traj_data\"  : None,\n",
    "                     \"goal_position\"     : None,\n",
    "                     \"one_hot_goal\"      : None}\n",
    "\n",
    "        test_set  = {\"history_traj_data\" : None,\n",
    "                     \"future_traj_data\"  : None,\n",
    "                     \"goal_position\"     : None,\n",
    "                     \"one_hot_goal\"      : None}\n",
    "        \n",
    "        # Train Set\n",
    "        for fold in train_inds:\n",
    "            search_str = 'fold_%d' % fold\n",
    "            search_res = np.argwhere([search_str in f for f in pklfiles_to_process])\n",
    "            assert(len(search_res) == 1)\n",
    "            file_num = search_res[0][0]\n",
    "            history_traj_data, future_traj_data, goals_position, one_hot_goal = extract_data(pklfiles_to_process[file_num])\n",
    "\n",
    "            if train_set['history_traj_data'] is None:\n",
    "                train_set['history_traj_data'] = history_traj_data\n",
    "                train_set['future_traj_data']  = future_traj_data\n",
    "                train_set['goal_position']     = goals_position\n",
    "                train_set['one_hot_goal']      = one_hot_goal         \n",
    "            else:\n",
    "                train_set['history_traj_data'] = np.append(train_set['history_traj_data'], history_traj_data, axis=0)\n",
    "                train_set['future_traj_data']  = np.append(train_set['future_traj_data'], future_traj_data, axis=0)\n",
    "                train_set['goal_position']     = np.append(train_set['goal_position'], goals_position, axis=0)\n",
    "                train_set['one_hot_goal']      = np.append(train_set['one_hot_goal'], one_hot_goal, axis=0)\n",
    "\n",
    "        # Test Set\n",
    "        for fold in [hold_out_ind]:\n",
    "            search_str = 'fold_%d' % fold\n",
    "            search_res = np.argwhere([search_str in f for f in pklfiles_to_process])\n",
    "            assert(len(search_res) == 1)\n",
    "            file_num = search_res[0][0]\n",
    "            history_traj_data, future_traj_data, goals_position, one_hot_goal = extract_data(pklfiles_to_process[file_num])\n",
    "\n",
    "            if test_set['history_traj_data'] is None:\n",
    "                test_set['history_traj_data'] = history_traj_data\n",
    "                test_set['future_traj_data']  = future_traj_data\n",
    "                test_set['goal_position']     = goals_position\n",
    "                test_set['one_hot_goal']      = one_hot_goal         \n",
    "            else:\n",
    "                test_set['history_traj_data'] = np.append(test_set['history_traj_data'], history_traj_data, axis=0)\n",
    "                test_set['future_traj_data']  = np.append(test_set['future_traj_data'], future_traj_data, axis=0)\n",
    "                test_set['goal_position']     = np.append(test_set['goal_position'], goals_position, axis=0)\n",
    "                test_set['one_hot_goal']      = np.append(test_set['one_hot_goal'], one_hot_goal, axis=0)\n",
    "                \n",
    "        train_sets.append(train_set)\n",
    "        test_sets.append(test_set)\n",
    "        \n",
    "    return train_sets, test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Construct the evaluation datasets.\n",
    "pklfiles_to_process = glob.glob('./dataset/*.pkl')\n",
    "pklfiles_to_process.sort()\n",
    "train_sets, test_sets = build_train_test_splits(pklfiles_to_process, num_pkl_folds=5)\n",
    "\n",
    "# Build the model bank.\n",
    "models = [] #TODO, LSTM + EKF\n",
    "model = EKF_CV_MODEL(x_init=np.zeros(5),\n",
    "                     P_init=np.eye(5),\n",
    "                     R=np.diag([1e-3]*3),\n",
    "                     dt=0.1)\n",
    "\n",
    "metrics = []\n",
    "\n",
    "for train_set, test_set in zip(train_sets, test_sets):\n",
    "    model.fit(train_set, test_set)\n",
    "    goal_pred, traj_pred = model.predict(test_set)\n",
    "    model.save()\n",
    "    metrics.append(evaluate_model(model))\n",
    "\n",
    "    # TODO: compute metrics and store in an array for final results.\n",
    "    # keras/sklearn metrics used for common evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: port Xu's visualization code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
