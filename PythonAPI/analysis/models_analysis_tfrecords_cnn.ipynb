{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-weight:bold\"> Currently used to prototype CNN on old dataset (Dec 2019). </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "from scipy.special import entr # see https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.entr.html\n",
    "from keras.utils import to_categorical\n",
    "import keras.metrics as metrics\n",
    "from kf_impl import EKF_CV_MODEL\n",
    "from lstm_impl import CombinedLSTM\n",
    "from cnn_lstm_impl import CombinedCNNLSTM\n",
    "import pdb\n",
    "from utils import extract_data, sup_plot\n",
    "import random\n",
    "from tfrecord_utils import  read_tfrecord\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_splits(tf_files_list, num_tf_folds=5):\n",
    "    # Using a suboptimal approach here:\n",
    "    # Just build a list of dictionaries, where entry_i \n",
    "    # corresponds to train split i.\n",
    "\n",
    "    train_sets = []\n",
    "    test_sets  = []\n",
    "     \n",
    "    for test_fold_ind in range(num_tf_folds):\n",
    "        train_set = [x for x in tf_files_list if int(x.split('/')[-1].split('_')[2]) != test_fold_ind]\n",
    "        test_set = [x for x in tf_files_list if int(x.split('/')[-1].split('_')[2]) == test_fold_ind]\n",
    "        \n",
    "        train_sets.append(train_set)\n",
    "        test_sets.append(test_set)\n",
    "        \n",
    "    return train_sets, test_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_dist_by_timestep(goal_pred, traj_pred_dict, traj_actual):\n",
    "    # M = # of instances, N = time horizon, 2 (xy) \n",
    "    M = traj_pred_dict[0].shape[0]\n",
    "    N = traj_pred_dict[0].shape[1]\n",
    "    \n",
    "    weighted_sum = np.zeros((M, N))\n",
    "    num_pred_traj = len(traj_pred_dict.keys())\n",
    "    top_k_probs = -np.sort(-goal_pred, axis=1)[:,:num_pred_traj]\n",
    "    \n",
    "    for k in range(num_pred_traj):\n",
    "        # key = 0 \n",
    "        traj_pred_k = traj_pred_dict[k] # M by N by 2\n",
    "        diff = traj_pred_k - traj_actual # M by N by 2\n",
    "        diff_xy_norm = np.linalg.norm(diff, axis=2) # M by N\n",
    "\n",
    "        for i in range(N):\n",
    "            diff_xy_norm[:,i] *= top_k_probs[:,k]\n",
    "        \n",
    "        weighted_sum += diff_xy_norm\n",
    "    return np.mean(weighted_sum, axis=0)\n",
    "\n",
    "def dist_by_timestep(traj_pred_dict, traj_actual):\n",
    "    # returns avg, min, max distance error across each timestep\n",
    "    diff = traj_pred_dict[0] - traj_actual # N by N_pred by 2\n",
    "    diff_xy_norm = np.linalg.norm(diff, axis=2)\n",
    "    return np.mean(diff_xy_norm, axis=0), np.min(diff_xy_norm, axis = 0), np.max(diff_xy_norm, axis=0)\n",
    "\n",
    "def top_k_accuracy(goal_pred, goal_actual, k=1):\n",
    "    # returns empirical probability of the real goal being contained\n",
    "    # in the top k most likely goal set from goal_pred.\n",
    "    return np.mean(metrics.top_k_categorical_accuracy(goal_actual, goal_pred, k=k))\n",
    "\n",
    "def mean_entropy(goal_pred):\n",
    "    # returns the avg. entropy of the goal prediction dist.\n",
    "    # higher entropy indicates more uncertain predictions\n",
    "    N = goal_pred.shape[0]\n",
    "    \n",
    "    entr_matrix = entr(goal_pred)\n",
    "    entr_by_instance = np.sum(entr_matrix, axis=1) #entropy by snippet\n",
    "    return np.mean(entr_by_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct the evaluation datasets.\n",
    "MODE = 'TRAIN' # 'TRAIN' or 'LOAD'\n",
    "res_filename = 'model_comparison_dict_12_2019.pkl'\n",
    "\n",
    "tfrecord_search_str = '/media/data/carla_parking_data_bkcp/dataset_12_2019/dataset*.tfrecord'\n",
    "model_dir = './model_cnn'\n",
    "results_dir = './results_cnn'\n",
    "\n",
    "# Create saving directories.\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "tffiles_to_process = glob.glob(tfrecord_search_str)\n",
    "train_sets, test_sets = build_train_test_splits(tffiles_to_process, num_tf_folds=5)\n",
    "\n",
    "# Build the model bank.\n",
    "models = []\n",
    "names = []\n",
    "\n",
    "# Build Trajectory Model\n",
    "# history_shape = train_sets[0]['history_traj_data'].shape\n",
    "# goal_position_shape = train_sets[0]['goal_position'].shape\n",
    "# one_hot_goal_shape = train_sets[0]['one_hot_goal'].shape\n",
    "# future_shape = train_sets[0]['future_traj_data'].shape\n",
    "# Hard coded for now, need to make this more robust:\n",
    "history_shape       = (None, 5, 3)\n",
    "goal_position_shape = (None, 32*3)\n",
    "one_hot_goal_shape  = (None, 32+1)\n",
    "future_shape        = (None, 20, 2)\n",
    "image_input_shape = (5,325,100,3)\n",
    "hidden_dim = 100\n",
    "top_k_goal = [0,1,2]\n",
    "\n",
    "\n",
    "gamma = 1.0\n",
    "for beta in [0.1, 0.5, 1.0]:        \n",
    "    models.append(\n",
    "        CombinedCNNLSTM(history_shape,\n",
    "                     goal_position_shape,\n",
    "                     image_input_shape,\n",
    "                     one_hot_goal_shape,\n",
    "                     future_shape,\n",
    "                     hidden_dim,\n",
    "                     beta=beta,\n",
    "                     gamma=gamma,\n",
    "                     use_goal_info=True))\n",
    "    names.append('CNN_b%.3f_g%.3f' % (beta,gamma))\n",
    "\n",
    "    models.append(\n",
    "            CombinedLSTM(history_shape,\n",
    "                         goal_position_shape,\n",
    "                         one_hot_goal_shape,\n",
    "                         future_shape,\n",
    "                         hidden_dim,\n",
    "                         beta=beta,\n",
    "                         gamma=gamma,\n",
    "                         use_goal_info=True)\n",
    "        )\n",
    "    names.append('LSTM_b%.3f_g%.3f' % (beta,gamma))\n",
    "    \n",
    "models.append(\n",
    "        CombinedCNNLSTM(history_shape,\n",
    "                     goal_position_shape,\n",
    "                     image_input_shape,\n",
    "                     one_hot_goal_shape,\n",
    "                     future_shape,\n",
    "                     hidden_dim,\n",
    "                     beta=beta,\n",
    "                     gamma=gamma,\n",
    "                     use_goal_info=False))\n",
    "names.append('CNN_no_goal')\n",
    "\n",
    "models.append(\n",
    "        CombinedLSTM(history_shape,\n",
    "                     goal_position_shape,\n",
    "                     one_hot_goal_shape,\n",
    "                     future_shape,\n",
    "                     hidden_dim,\n",
    "                     beta=beta,\n",
    "                     gamma=gamma,\n",
    "                     use_goal_info=False))\n",
    "names.append('LSTM_no_goal')\n",
    "\n",
    "        \n",
    "model_res_dict = {} # same indexing/length as names/models\n",
    "if MODE is 'TRAIN':\n",
    "    for name, model in zip(names, models):\n",
    "        metric_dict = {}\n",
    "        metric_dict['train'] = {'N_instances'   : [],\n",
    "                                'traj_dist_vs_N': [],   # no goal\n",
    "                                'wtraj_dist_vs_N': [],  # weighted, multimodal\n",
    "                                'gtraj_dist_vs_N': [],  # gt\n",
    "                                'goal_top_1_acc': [], \n",
    "                                'goal_top_3_acc': [],\n",
    "                                'goal_top_5_acc': [],\n",
    "                                'goal_entropy'  : []}\n",
    "        metric_dict['test']  = {'N_instances'   : [],\n",
    "                                'traj_dist_vs_N': [],   # no goal\n",
    "                                'wtraj_dist_vs_N': [],  # weighted, multimodal\n",
    "                                'gtraj_dist_vs_N': [],  # gt\n",
    "                                'goal_top_1_acc': [], \n",
    "                                'goal_top_3_acc': [],\n",
    "                                'goal_top_5_acc': [],\n",
    "                                'goal_entropy'  : []}\n",
    "\n",
    "        for i_fold, (train_set, test_set) in enumerate(zip(train_sets, test_sets)):\n",
    "            \n",
    "            print('Training %s, Fold %d at ' % (name, i_fold), time.time())\n",
    "            if 'LSTM' in name or 'CNN' in name:\n",
    "                model.fit(train_set, test_set, num_epochs=200, batch_size=32, verbose=1)\n",
    "            elif 'EKF' in name:\n",
    "                model.fit(train_set, test_set)\n",
    "            else:\n",
    "                raise ValueError(\"invalid model for testing\")\n",
    "                \n",
    "            model.save('%s/%s_fold%d' % (model_dir, name, i_fold))\n",
    "            \n",
    "            for tkey, tset in zip(['train', 'test'], [train_set, test_set]):\n",
    "                print('\\tStarted prediction for tkey: ', tkey, ' at ', time.time())\n",
    "                goal_pred, goal_gt, traj_pred_dict, traj_gt = model.predict(tset) # either no goal or ground truth\n",
    "                N_instances = goal_pred.shape[0]\n",
    "                \n",
    "                if 'no_goal' in name or 'EKF_CV' in name:\n",
    "                    # just populate the traj_dist_vs_N\n",
    "                    meand, mind, maxd = dist_by_timestep(traj_pred_dict, traj_gt[:,:,:2])\n",
    "                    metric_dict[tkey]['traj_dist_vs_N'].append(meand)\n",
    "                else:\n",
    "                    # ugly hack: every multimodal case can keep the same gt result.\n",
    "                    # just look up one multimodal case for plotting.\n",
    "                    meand, mind, maxd = dist_by_timestep(traj_pred_dict, traj_gt[:,:,:2])\n",
    "                    metric_dict[tkey]['gtraj_dist_vs_N'].append(meand)\n",
    "                    \n",
    "                    # multimodal predictions with weighted distance by timestep.\n",
    "                    goal_pred, goal_gt, traj_pred_dict, traj_gt = model.predict(tset, top_k_goal)\n",
    "                    wmeand = weighted_dist_by_timestep(goal_pred, traj_pred_dict, traj_gt[:,:,:2])\n",
    "                    metric_dict[tkey]['wtraj_dist_vs_N'].append(wmeand)\n",
    "                \n",
    "                t1 = top_k_accuracy(goal_pred, goal_gt, k=1)\n",
    "                t3 = top_k_accuracy(goal_pred, goal_gt, k=3)\n",
    "                t5 = top_k_accuracy(goal_pred, goal_gt, k=5)\n",
    "\n",
    "                ment = mean_entropy(goal_pred)\n",
    "                metric_dict[tkey]['N_instances'].append(N_instances)\n",
    "                metric_dict[tkey]['goal_top_1_acc'].append(t1)\n",
    "                metric_dict[tkey]['goal_top_3_acc'].append(t3)\n",
    "                metric_dict[tkey]['goal_top_5_acc'].append(t5)\n",
    "                metric_dict[tkey]['goal_entropy'].append(ment)\n",
    "                # TODO: save predictions/labels?\n",
    "            \n",
    "        model_res_dict[name] = metric_dict\n",
    "        print('Finished model: ', name)\n",
    "\n",
    "    # save the model_res_dict to ./results\n",
    "    pickle.dump(model_res_dict, open('%s/%s' % (results_dir, res_filename), 'wb'))\n",
    "elif MODE is 'LOAD':\n",
    "    # TODO: maybe load models if needed?\n",
    "    model_res_dict = pickle.load(open('%s/%s' % (results_dir, res_filename), 'rb'))\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: visualize the snippets.  Needs to be done with tfrecord.\n",
    "'''\n",
    "# Get the data\n",
    "pklfiles_to_process = glob.glob('./dataset/*.pkl')\n",
    "pklfiles_to_process.sort()\n",
    "print('Found %d pkl files: %s' % (len(pklfiles_to_process), pklfiles_to_process))\n",
    "\n",
    "file_num = 0\n",
    "\n",
    "pklfile = pklfiles_to_process[file_num]\n",
    "\n",
    "vtest_set  = {\"history_traj_data\" : None,\n",
    "             \"future_traj_data\"  : None,\n",
    "             \"goal_position\"     : None,\n",
    "             \"one_hot_goal\"      : None}\n",
    "vtest_set_kf  = {\"history_traj_data\" : None,\n",
    "             \"future_traj_data\"  : None,\n",
    "             \"goal_position\"     : None,\n",
    "             \"one_hot_goal\"      : None}\n",
    "\n",
    "vtest_set['history_traj_data'], vtest_set['future_traj_data'], vtest_set['goal_position'], vtest_set['one_hot_goal'], traj_idx = extract_data(pklfile, full_traj=True, crop_traj=True)\n",
    "vtest_set_kf['history_traj_data'], vtest_set_kf['future_traj_data'], vtest_set_kf['goal_position'], vtest_set_kf['one_hot_goal'], traj_idx_kf = extract_data(pklfile, full_traj=True, crop_traj=False)\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    if 'EKF_CV' in name:\n",
    "        goal_pred, traj_pred_dict = model.predict(vtest_set_kf)\n",
    "    elif 'no_goal' in name:\n",
    "        continue\n",
    "    else:\n",
    "        goal_pred, traj_pred_dict = model.predict(vtest_set, top_k_goal=top_k_goal)\n",
    "        \n",
    "    sup_plot(name, vtest_set, traj_idx, goal_pred, traj_pred_dict, limit=2)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLOT 1: timestep vs. mean distance error\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data_list = []\n",
    "timesteps = np.arange(20) # TODO: hard coded for now, change later.\n",
    "\n",
    "for model in model_res_dict.keys():\n",
    "    for split in model_res_dict[model].keys(): \n",
    "        # train/test\n",
    "        if 'no_goal' in model:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "        elif 'EKF' in model:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "        # hack to only get ground truth goal based traj. pred once\n",
    "        elif 'b1.000_g1.000' in model:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['gtraj_dist_vs_N']\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "        for i_fold, td in enumerate(traj_dist_vs_N):\n",
    "            for j_timestep, dist_timestep in enumerate(td):\n",
    "                data_list.append([name, split, i_fold, j_timestep, dist_timestep])\n",
    "            \n",
    "traj_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Timestep', 'Distance Error'],dtype=float)\n",
    "print(traj_df)\n",
    "\n",
    "print('TRAIN')\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=traj_df[traj_df.Split == 'train'])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()\n",
    "\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=traj_df[(traj_df.Split == 'train') & \\\n",
    "                                                                              (traj_df.Model != 'EKF_CV')])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()\n",
    "\n",
    "print('TEST')\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=traj_df[traj_df.Split == 'test'])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()\n",
    "\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=traj_df[(traj_df.Split == 'test') & \\\n",
    "                                                                              (traj_df.Model != 'EKF_CV')])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLOT 2: timestep vs. weighted mean distance error\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data_list = []\n",
    "timesteps = np.arange(20) # TODO: hard coded for now, change later.\n",
    "\n",
    "for model in model_res_dict.keys():\n",
    "    for split in model_res_dict[model].keys(): \n",
    "        # train/test\n",
    "        if 'no_goal' in model:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "        elif 'EKF' in model:\n",
    "            continue\n",
    "        else:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['wtraj_dist_vs_N']  \n",
    "            \n",
    "        for i_fold, td in enumerate(traj_dist_vs_N):\n",
    "            for j_timestep, dist_timestep in enumerate(td):\n",
    "                data_list.append([name, split, i_fold, j_timestep, dist_timestep])\n",
    "\n",
    "# gtraj_dist_vs_N_test = model_res_dict['LSTM_b0.100_g0.100']['test'] ['gtraj_dist_vs_N'] \n",
    "# for i_fold, td in enumerate(gtraj_dist_vs_N_test):\n",
    "#     for j_timestep, dist_timestep in enumerate(td):\n",
    "#         data_list.append(['LSTM_gt_goal', 'test', i_fold, j_timestep, dist_timestep])\n",
    "\n",
    "# gtraj_dist_vs_N_train = model_res_dict['LSTM_b0.100_g0.001']['train']['gtraj_dist_vs_N'] \n",
    "# for i_fold, td in enumerate(gtraj_dist_vs_N_train):\n",
    "#     for j_timestep, dist_timestep in enumerate(td):\n",
    "#         data_list.append(['LSTM_gt_goal', 'train', i_fold, j_timestep, dist_timestep])\n",
    "                \n",
    "traj_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Timestep', 'Weighted Distance Error'],dtype=float)\n",
    "traj_df_test = traj_df[traj_df.Split == 'test']\n",
    "print(traj_df_test)\n",
    "\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Weighted Distance Error\", hue=\"Model\", data=traj_df_test)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()\n",
    "\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Weighted Distance Error\", hue=\"Model\", data=traj_df_test[(traj_df.Model == 'LSTM_no_goal') | \n",
    "                                                                                            (traj_df.Model == 'LSTM_gt_goal')])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 3: Top K accuracy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data_list = []\n",
    "# timesteps = np.arange(20) # TODO: hard coded for now, change later.\n",
    "\n",
    "for model in model_res_dict.keys():\n",
    "    if 'no_goal' in model:\n",
    "        continue\n",
    "    for split in model_res_dict[model].keys():\n",
    "        \n",
    "        \n",
    "        #train/test\n",
    "        \n",
    "        goal_top_1_acc = model_res_dict[model][split]['goal_top_1_acc']\n",
    "        goal_top_3_acc = model_res_dict[model][split]['goal_top_3_acc']\n",
    "        goal_top_5_acc = model_res_dict[model][split]['goal_top_5_acc']\n",
    "#         goal_entropy   = model_res_dict[model][split]['goal_entropy']\n",
    "        \n",
    "        for i_fold, (t1, t3, t5) in enumerate(zip(goal_top_1_acc, \n",
    "                                                       goal_top_3_acc,\n",
    "                                                       goal_top_5_acc)):\n",
    "            data_list.append([model, split, i_fold, 1, t1])\n",
    "            data_list.append([model, split, i_fold, 3, t3])\n",
    "            data_list.append([model, split, i_fold, 5, t5])\n",
    "            \n",
    "goal_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'k', 'Accuracy'],dtype=float)\n",
    "goal_test_df = goal_df[goal_df.Split == 'test']\n",
    "\n",
    "# Make a bar chart out of this.\n",
    "ax = sns.barplot(x='k', y='Accuracy', hue='Model', data=goal_df.sort_values(by=['Model']))\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 4: Entropy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data_list = []\n",
    "\n",
    "for model in model_res_dict.keys():\n",
    "    if 'no_goal' in model:\n",
    "        continue\n",
    "    for split in model_res_dict[model].keys():\n",
    "        #train/test\n",
    "        goal_entropy   = model_res_dict[model][split]['goal_entropy']\n",
    "        \n",
    "        for i_fold, ent in enumerate(goal_entropy):\n",
    "            data_list.append([model, split, i_fold, ent])\n",
    "            \n",
    "goal_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Entropy'],dtype=float)\n",
    "goal_test_df = goal_df[goal_df.Split == 'test']\n",
    "\n",
    "# Make a bar chart out of this.\n",
    "ax = sns.barplot(x='Model', y='Entropy', data=goal_df.sort_values(by=['Model']))\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
