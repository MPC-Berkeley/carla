{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from scipy.special import entr # see https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.entr.html\n",
    "from keras.utils import to_categorical\n",
    "import keras.metrics as metrics\n",
    "from kf_impl import EKF_CV_MODEL\n",
    "from lstm_impl import CombinedLSTM\n",
    "import pdb\n",
    "from utils import extract_data, sup_plot\n",
    "import random\n",
    "from tfrecord_utils import  read_tfrecord\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_test_splits(tf_files_list, num_tf_folds=5):\n",
    "    # Using a suboptimal approach here:\n",
    "    # Just build a list of dictionaries, where entry_i \n",
    "    # corresponds to train split i.\n",
    "\n",
    "    train_sets = []\n",
    "    test_sets  = []\n",
    "    folds  = []\n",
    "    \n",
    "    inds = np.arange(num_tf_folds)\n",
    "    \n",
    "    random.shuffle(tf_files_list)\n",
    "    n_files = len(tf_files_list)\n",
    "    \n",
    "    \n",
    "    splits = (n_files // num_tf_folds) * np.ones(num_tf_folds)\n",
    "    splits[:n_files % num_tf_folds] += 1\n",
    "    \n",
    "    ind_limits = np.cumsum(splits).astype(np.int)\n",
    "    \n",
    "    for i in range(len(ind_limits)):\n",
    "        if i == 0:\n",
    "            ind_start = 0\n",
    "        else:\n",
    "            ind_start = ind_limits[i-1]\n",
    "        ind_end = ind_limits[i]\n",
    "        \n",
    "        folds.append(tf_files_list[ind_start:ind_end])\n",
    "\n",
    "    flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "    for hold_out_ind in inds:\n",
    "        train_inds = np.delete(inds, hold_out_ind)\n",
    "        test_inds = [hold_out_ind]\n",
    "        \n",
    "        train_sets.append(flatten([y for y in [folds[x] for x in train_inds]]))\n",
    "        test_sets.append(flatten([y for y in [folds[x] for x in test_inds]]))\n",
    "                \n",
    "    return train_sets, test_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_dist_by_timestep(goal_pred, traj_pred_dict, traj_actual):\n",
    "    # M = # of instances, N = time horizon, 2 (xy) \n",
    "    M = traj_pred_dict[0].shape[0]\n",
    "    N = traj_pred_dict[0].shape[1]\n",
    "    \n",
    "    weighted_sum = np.zeros((M, N))\n",
    "    num_pred_traj = len(traj_pred_dict.keys())\n",
    "    top_k_probs = -np.sort(-goal_pred, axis=1)[:,:num_pred_traj]\n",
    "    \n",
    "    for k in range(num_pred_traj):\n",
    "        # key = 0 \n",
    "        traj_pred_k = traj_pred_dict[k] # M by N by 2\n",
    "        diff = traj_pred_k - traj_actual # M by N by 2\n",
    "        diff_xy_norm = np.linalg.norm(diff, axis=2) # M by N\n",
    "\n",
    "        for i in range(N):\n",
    "            diff_xy_norm[:,i] *= top_k_probs[:,k]\n",
    "        \n",
    "        weighted_sum += diff_xy_norm\n",
    "    return np.mean(weighted_sum, axis=0)\n",
    "\n",
    "def dist_by_timestep(traj_pred_dict, traj_actual):\n",
    "    # returns avg, min, max distance error across each timestep\n",
    "    diff = traj_pred_dict[0] - traj_actual # N by N_pred by 2\n",
    "    diff_xy_norm = np.linalg.norm(diff, axis=2)\n",
    "    return np.mean(diff_xy_norm, axis=0), np.min(diff_xy_norm, axis = 0), np.max(diff_xy_norm, axis=0)\n",
    "\n",
    "def top_k_accuracy(goal_pred, goal_actual, k=1):\n",
    "    # returns empirical probability of the real goal being contained\n",
    "    # in the top k most likely goal set from goal_pred.\n",
    "    return np.mean(metrics.top_k_categorical_accuracy(goal_actual, goal_pred, k=k))\n",
    "\n",
    "def mean_entropy(goal_pred):\n",
    "    # returns the avg. entropy of the goal prediction dist.\n",
    "    # higher entropy indicates more uncertain predictions\n",
    "    N = goal_pred.shape[0]\n",
    "    \n",
    "    entr_matrix = entr(goal_pred)\n",
    "    entr_by_instance = np.sum(entr_matrix, axis=1) #entropy by snippet\n",
    "    return np.mean(entr_by_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Save Models and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Construct the evaluation   datasets.\\nMODE = 'TRAIN' # 'TRAIN' or 'LOAD'\\n\\ntffiles_to_process = glob.glob('../examples/bags/*.tfrecord')\\ntrain_sets, test_sets = build_train_test_splits(tffiles_to_process, num_tf_folds=5)\\nhistory_shape       = (None, 5, 3)\\ngoal_position_shape = (None, 32*3)\\none_hot_goal_shape  = (None, 32+1)\\nfuture_shape        = (None, 20, 2)\\nimage_input_shape = (5,650,200,3)\\nhidden_dim = 100\\ntop_k_goal = [0,1,2]\\n\\nmodel = CombinedLSTM(history_shape,\\n                 goal_position_shape,\\n                 image_input_shape,\\n                 one_hot_goal_shape,\\n                 future_shape,\\n                 hidden_dim,\\n                 beta=1,\\n                 gamma=1,\\n                 use_goal_info=False)\\n#model.fit(train_sets[0], test_sets[0],verbose=1)\\n\\ngoal_pred, goal_gt, traj_pred_dict, traj_gt = model.predict(test_sets[1])\\nprint(goal_pred.shape,goal_gt.shape,traj_pred_dict[0].shape,traj_gt.shape)\\n#print(np.sum(goal_gt,axis=0))\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Construct the evaluation   datasets.\n",
    "MODE = 'TRAIN' # 'TRAIN' or 'LOAD'\n",
    "\n",
    "tffiles_to_process = glob.glob('../examples/bags/*.tfrecord')\n",
    "train_sets, test_sets = build_train_test_splits(tffiles_to_process, num_tf_folds=5)\n",
    "history_shape       = (None, 5, 3)\n",
    "goal_position_shape = (None, 32*3)\n",
    "one_hot_goal_shape  = (None, 32+1)\n",
    "future_shape        = (None, 20, 2)\n",
    "image_input_shape = (5,650,200,3)\n",
    "hidden_dim = 100\n",
    "top_k_goal = [0,1,2]\n",
    "\n",
    "model = CombinedLSTM(history_shape,\n",
    "                 goal_position_shape,\n",
    "                 image_input_shape,\n",
    "                 one_hot_goal_shape,\n",
    "                 future_shape,\n",
    "                 hidden_dim,\n",
    "                 beta=1,\n",
    "                 gamma=1,\n",
    "                 use_goal_info=False)\n",
    "#model.fit(train_sets[0], test_sets[0],verbose=1)\n",
    "\n",
    "goal_pred, goal_gt, traj_pred_dict, traj_gt = model.predict(test_sets[1])\n",
    "print(goal_pred.shape,goal_gt.shape,traj_pred_dict[0].shape,traj_gt.shape)\n",
    "#print(np.sum(goal_gt,axis=0))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_trajectory_20:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_41/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_21:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_43/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_22:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_45/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_23:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_47/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_24:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_49/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_25:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_51/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_26:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_53/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_27:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_55/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_28:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_57/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Tensor(\"input_trajectory_29:0\", shape=(None, 5, 3), dtype=float32)\n",
      "Lstm cnn Tensor(\"concatenate_59/concat:0\", shape=(None, 5, 13), dtype=float32)\n",
      "Training EKF_CV, Fold 0\n",
      "Training LSTM_b0.001_g0.001, Fold 0\n",
      "WARNING:tensorflow:From /Users/batko/Desktop/Papers/Berkeley/carla/PythonAPI/analysis/tfrecord_utils.py:82: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-172787e2c33e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training %s, Fold %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/%s_fold%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/carla/PythonAPI/analysis/lstm_impl.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_set, val_set, batch_size, verbose, use_image)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraj_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_goal_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_goal_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muse_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/carla/PythonAPI/analysis/lstm_impl.py\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(self, train_set, val_set, num_epochs, batch_size, verbose, use_image)\u001b[0m\n\u001b[1;32m    190\u001b[0m \t\t\t\t\tverbose=verbose)\n\u001b[1;32m    191\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/park/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/park/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/park/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/park/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/park/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/park/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/park/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Desktop/Papers/Berkeley/park/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#  TODO: Vijay\n",
    "\n",
    "# Construct the evaluation datasets.\n",
    "MODE = 'TRAIN' # 'TRAIN' or 'LOAD'\n",
    "res_filename = 'model_comparison_dict.pkl'\n",
    "\n",
    "tffiles_to_process = glob.glob('../examples/bags/*.tfrecord')\n",
    "train_sets, test_sets = build_train_test_splits(tffiles_to_process, num_tf_folds=5)\n",
    "\n",
    "# Build the model bank.\n",
    "models = [EKF_CV_MODEL(x_init=np.zeros(5), P_init=np.eye(5), R=np.diag([1e-3]*3), dt=0.1)]\n",
    "names =  ['EKF_CV']\n",
    "\n",
    "# Create saving directories.\n",
    "if not os.path.exists('./model'):\n",
    "    os.makedirs('./model')\n",
    "if not os.path.exists('./results'):\n",
    "    os.makedirs('./results')\n",
    "\n",
    "# Build Trajectory Model\n",
    "# history_shape = train_sets[0]['history_traj_data'].shape\n",
    "# goal_position_shape = train_sets[0]['goal_position'].shape\n",
    "# one_hot_goal_shape = train_sets[0]['one_hot_goal'].shape\n",
    "# future_shape = train_sets[0]['future_traj_data'].shape\n",
    "# Hard coded for now, need to make this more robust:\n",
    "history_shape       = (None, 5, 3)\n",
    "goal_position_shape = (None, 32*3)\n",
    "one_hot_goal_shape  = (None, 32+1)\n",
    "future_shape        = (None, 20, 2)\n",
    "image_input_shape = (5,650,200,3)\n",
    "hidden_dim = 100\n",
    "top_k_goal = [0,1,2]\n",
    "\n",
    "\n",
    "for gamma in [0.001, 0.1, 1.0]:\n",
    "    for beta in [0.001, 0.1, 1.0]:\n",
    "        models.append(\n",
    "            CombinedLSTM(history_shape,\n",
    "                         goal_position_shape,\n",
    "                         image_input_shape,\n",
    "                         one_hot_goal_shape,\n",
    "                         future_shape,\n",
    "                         hidden_dim,\n",
    "                         beta=beta,\n",
    "                         gamma=gamma,\n",
    "                         use_goal_info=True)\n",
    "        )\n",
    "    \n",
    "        names.append('LSTM_b%.3f_g%.3f' % (beta, gamma)) # ground truth goal, anyone can be used for traj LSTM\n",
    "\n",
    "models.append(\n",
    "    CombinedLSTM(history_shape,\n",
    "                 goal_position_shape,\n",
    "                 image_input_shape,\n",
    "                 one_hot_goal_shape,\n",
    "                 future_shape,\n",
    "                 hidden_dim,\n",
    "                 beta=beta,\n",
    "                 gamma=gamma,\n",
    "                 use_goal_info=False)\n",
    ") # no goal provided, beta gamma irrelevant, don't use for goal classification\n",
    "\n",
    "names.append('LSTM_no_goal')\n",
    "train_sets = [train_sets[0]]\n",
    "tesst_sets = [test_sets[0]]\n",
    "model_res_dict = {} # same indexing/length as names/models\n",
    "if MODE is 'TRAIN':\n",
    "    for name, model in zip(names, models):\n",
    "        metric_dict = {}\n",
    "        metric_dict['train'] = {'N_instances'   : [],\n",
    "                                'traj_dist_vs_N': [],   # no goal\n",
    "                                'wtraj_dist_vs_N': [],  # weighted, multimodal\n",
    "                                'gtraj_dist_vs_N': [],  # gt\n",
    "                                'goal_top_1_acc': [], \n",
    "                                'goal_top_3_acc': [],\n",
    "                                'goal_top_5_acc': [],\n",
    "                                'goal_entropy'  : []}\n",
    "        metric_dict['test']  = {'N_instances'   : [],\n",
    "                                'traj_dist_vs_N': [],   # no goal\n",
    "                                'wtraj_dist_vs_N': [],  # weighted, multimodal\n",
    "                                'gtraj_dist_vs_N': [],  # gt\n",
    "                                'goal_top_1_acc': [], \n",
    "                                'goal_top_3_acc': [],\n",
    "                                'goal_top_5_acc': [],\n",
    "                                'goal_entropy'  : []}\n",
    "\n",
    "        for i_fold, (train_set, test_set) in enumerate(zip(train_sets, test_sets)):\n",
    "            \n",
    "            print('Training %s, Fold %d' % (name, i_fold))\n",
    "            model.fit(train_set, test_set)\n",
    "            model.save('./model/%s_fold%d' % (name, i_fold))\n",
    "\n",
    "            for tkey, tset in zip(['train', 'test'], [train_set, test_set]):\n",
    "\n",
    "                goal_pred, goal_gt, traj_pred_dict, traj_gt = model.predict(tset) # either no goal or ground truth\n",
    "                N_instances = goal_pred.shape[0]\n",
    "                \n",
    "                if 'no_goal' in name or 'EKF_CV' in name:\n",
    "                    # just populate the traj_dist_vs_N\n",
    "                    meand, mind, maxd = dist_by_timestep(traj_pred_dict, traj_gt[:,:,:2])\n",
    "                    metric_dict[tkey]['traj_dist_vs_N'].append(meand)\n",
    "                else:\n",
    "                    meand, mind, maxd = dist_by_timestep(traj_pred_dict, traj_gt[:,:,:2])\n",
    "                    metric_dict[tkey]['gtraj_dist_vs_N'].append(meand)\n",
    "                    \n",
    "                    goal_pred, traj_pred_dict = model.predict(tset, top_k_goal)\n",
    "                    wmeand = weighted_dist_by_timestep(goal_pred, traj_pred_dict, traj_gt[:,:,:2])\n",
    "                    metric_dict[tkey]['wtraj_dist_vs_N'].append(wmeand)\n",
    "                    # populate gtraj_dist_vs_N (gt)\n",
    "                    # and do multimodal\n",
    "                \n",
    "                t1 = top_k_accuracy(goal_pred, goal_gt, k=1)\n",
    "                t3 = top_k_accuracy(goal_pred, goal_gt, k=3)\n",
    "                t5 = top_k_accuracy(goal_pred, goal_gt, k=5)\n",
    "\n",
    "                ment = mean_entropy(goal_pred)\n",
    "                metric_dict[tkey]['N_instances'].append(N_instances)\n",
    "                metric_dict[tkey]['goal_top_1_acc'].append(t1)\n",
    "                metric_dict[tkey]['goal_top_3_acc'].append(t3)\n",
    "                metric_dict[tkey]['goal_top_5_acc'].append(t5)\n",
    "                metric_dict[tkey]['goal_entropy'].append(ment)\n",
    "\n",
    "                # TODO: save predictions/labels?\n",
    "\n",
    "        model_res_dict[name] = metric_dict\n",
    "\n",
    "    # save the model_res_dict to ./results\n",
    "    filename = 'model_comparison_dict.pkl'\n",
    "    pickle.dump(model_res_dict, open('./results/%s' % res_filename, 'wb'))\n",
    "elif MODE is 'LOAD':\n",
    "    # TODO: maybe load models if needed?\n",
    "    model_res_dict = pickle.load(open('./results/%s' % res_filename, 'rb'))\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "pklfiles_to_process = glob.glob('./dataset/*.pkl')\n",
    "pklfiles_to_process.sort()\n",
    "print('Found %d pkl files: %s' % (len(pklfiles_to_process), pklfiles_to_process))\n",
    "\n",
    "file_num = 0\n",
    "\n",
    "pklfile = pklfiles_to_process[file_num]\n",
    "\n",
    "vtest_set  = {\"history_traj_data\" : None,\n",
    "             \"future_traj_data\"  : None,\n",
    "             \"goal_position\"     : None,\n",
    "             \"one_hot_goal\"      : None}\n",
    "vtest_set_kf  = {\"history_traj_data\" : None,\n",
    "             \"future_traj_data\"  : None,\n",
    "             \"goal_position\"     : None,\n",
    "             \"one_hot_goal\"      : None}\n",
    "\n",
    "vtest_set['history_traj_data'], vtest_set['future_traj_data'], vtest_set['goal_position'], vtest_set['one_hot_goal'], traj_idx = extract_data(pklfile, full_traj=True, crop_traj=True)\n",
    "vtest_set_kf['history_traj_data'], vtest_set_kf['future_traj_data'], vtest_set_kf['goal_position'], vtest_set_kf['one_hot_goal'], traj_idx_kf = extract_data(pklfile, full_traj=True, crop_traj=False)\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    if 'EKF_CV' in name:\n",
    "        goal_pred, traj_pred_dict = model.predict(vtest_set_kf)\n",
    "    elif 'no_goal' in name:\n",
    "        continue\n",
    "    else:\n",
    "        goal_pred, traj_pred_dict = model.predict(vtest_set, top_k_goal=top_k_goal)\n",
    "        \n",
    "    sup_plot(name, vtest_set, traj_idx, goal_pred, traj_pred_dict, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 1: timestep vs. mean distance error\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data_list = []\n",
    "timesteps = np.arange(20) # TODO: hard coded for now, change later.\n",
    "\n",
    "for model in model_res_dict.keys():\n",
    "    for split in model_res_dict[model].keys(): \n",
    "        # train/test\n",
    "        if 'no_goal' in model:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "        elif 'EKF' in model:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "            # hack to only get ground truth goal based traj. pred once\n",
    "        elif 'b0.100_g0.100' in model:\n",
    "            name = 'LSTM_gt_goal'\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['gtraj_dist_vs_N']\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "        for i_fold, td in enumerate(traj_dist_vs_N):\n",
    "            for j_timestep, dist_timestep in enumerate(td):\n",
    "                data_list.append([name, split, i_fold, j_timestep, dist_timestep])\n",
    "            \n",
    "traj_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Timestep', 'Distance Error'],dtype=float)\n",
    "print(traj_df)\n",
    "\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=traj_df[traj_df.Split == 'test'])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()\n",
    "\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=traj_df[(traj_df.Split == 'test') & \\\n",
    "                                                                              (traj_df.Model != 'EKF_CV')])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 2: timestep vs. weighted mean distance error\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data_list = []\n",
    "timesteps = np.arange(20) # TODO: hard coded for now, change later.\n",
    "\n",
    "for model in model_res_dict.keys():\n",
    "    for split in model_res_dict[model].keys(): \n",
    "        # train/test\n",
    "        if 'no_goal' in model:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "        elif 'EKF' in model:\n",
    "            continue\n",
    "        else:\n",
    "            name = model\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['wtraj_dist_vs_N']  \n",
    "            \n",
    "        for i_fold, td in enumerate(traj_dist_vs_N):\n",
    "            for j_timestep, dist_timestep in enumerate(td):\n",
    "                data_list.append([name, split, i_fold, j_timestep, dist_timestep])\n",
    "\n",
    "gtraj_dist_vs_N_test = model_res_dict['LSTM_b0.100_g0.100']['test'] ['gtraj_dist_vs_N'] \n",
    "for i_fold, td in enumerate(gtraj_dist_vs_N_test):\n",
    "    for j_timestep, dist_timestep in enumerate(td):\n",
    "        data_list.append(['LSTM_gt_goal', 'test', i_fold, j_timestep, dist_timestep])\n",
    "\n",
    "gtraj_dist_vs_N_train = model_res_dict['LSTM_b0.100_g0.001']['train']['gtraj_dist_vs_N'] \n",
    "for i_fold, td in enumerate(gtraj_dist_vs_N_train):\n",
    "    for j_timestep, dist_timestep in enumerate(td):\n",
    "        data_list.append(['LSTM_gt_goal', 'train', i_fold, j_timestep, dist_timestep])\n",
    "                \n",
    "traj_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Timestep', 'Weighted Distance Error'],dtype=float)\n",
    "traj_df_test = traj_df[traj_df.Split == 'test']\n",
    "print(traj_df_test)\n",
    "\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Weighted Distance Error\", hue=\"Model\", data=traj_df_test)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()\n",
    "\n",
    "ax = sns.lineplot(x=\"Timestep\", y=\"Weighted Distance Error\", hue=\"Model\", data=traj_df_test[(traj_df.Model == 'LSTM_no_goal') | \n",
    "                                                                                            (traj_df.Model == 'LSTM_gt_goal')])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.ylabel('Distance Error (m)')\n",
    "plt.xticks(np.arange(0, 21, step=2))\n",
    "plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 3: Top K accuracy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data_list = []\n",
    "# timesteps = np.arange(20) # TODO: hard coded for now, change later.\n",
    "\n",
    "for model in model_res_dict.keys():\n",
    "    if 'no_goal' in model:\n",
    "        continue\n",
    "    for split in model_res_dict[model].keys():\n",
    "        \n",
    "        \n",
    "        #train/test\n",
    "        \n",
    "        goal_top_1_acc = model_res_dict[model][split]['goal_top_1_acc']\n",
    "        goal_top_3_acc = model_res_dict[model][split]['goal_top_3_acc']\n",
    "        goal_top_5_acc = model_res_dict[model][split]['goal_top_5_acc']\n",
    "#         goal_entropy   = model_res_dict[model][split]['goal_entropy']\n",
    "        \n",
    "        for i_fold, (t1, t3, t5) in enumerate(zip(goal_top_1_acc, \n",
    "                                                       goal_top_3_acc,\n",
    "                                                       goal_top_5_acc)):\n",
    "            data_list.append([model, split, i_fold, 1, t1])\n",
    "            data_list.append([model, split, i_fold, 3, t3])\n",
    "            data_list.append([model, split, i_fold, 5, t5])\n",
    "            \n",
    "goal_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'k', 'Accuracy'],dtype=float)\n",
    "goal_test_df = goal_df[goal_df.Split == 'test']\n",
    "\n",
    "# Make a bar chart out of this.\n",
    "ax = sns.barplot(x='k', y='Accuracy', hue='Model', data=goal_df.sort_values(by=['Model']))\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT 4: Entropy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "data_list = []\n",
    "\n",
    "for model in model_res_dict.keys():\n",
    "    if 'no_goal' in model:\n",
    "        continue\n",
    "    for split in model_res_dict[model].keys():\n",
    "        #train/test\n",
    "        goal_entropy   = model_res_dict[model][split]['goal_entropy']\n",
    "        \n",
    "        for i_fold, ent in enumerate(goal_entropy):\n",
    "            data_list.append([model, split, i_fold, ent])\n",
    "            \n",
    "goal_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Entropy'],dtype=float)\n",
    "goal_test_df = goal_df[goal_df.Split == 'test']\n",
    "\n",
    "# Make a bar chart out of this.\n",
    "ax = sns.barplot(x='Model', y='Entropy', data=goal_df.sort_values(by=['Model']))\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
