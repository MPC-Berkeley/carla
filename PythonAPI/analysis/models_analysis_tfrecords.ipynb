{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-weight:bold\"> Trains and runs predictions for all models.  Evaluation code (run on predictions) found in models_evaluation_tfrecords. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"      # choose which GPU to run on.\n",
    "\n",
    "# These are the models we want to evaluate (EKF, LSTM, CNN+LSTM)\n",
    "from kf_impl import EKF_CV_MODEL\n",
    "from lstm_impl import CombinedLSTM\n",
    "from cnn_lstm_impl import CombinedCNNLSTM\n",
    "\n",
    "from evaluation_metrics import build_train_test_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set notebook parameters (change each time you run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'PREDICT' # 'TRAIN'   : train models and save them in model_dir\n",
    "                 # 'PREDICT' : load trained models in model_dir and save predictions in results_dir\n",
    "\n",
    "# Dataset (tfrecords) specified via a search string.\n",
    "tfrecord_search_str = '../examples/bags/dataset_01_2020/dataset*.tfrecord'\n",
    "\n",
    "# Model directory where trained models are saved (if MODE is 'TRAIN')\n",
    "model_dir = './models'\n",
    "\n",
    "# Results directory where predictions are saved (if MODE is 'PREDICT')\n",
    "results_dir = './results'\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Predict Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(names, models, train_sets, model_dir, num_epochs=200, batch_size=32, verbose=1):\n",
    "    for name, model in zip(names, models):\n",
    "        for i_fold, train_set in enumerate(train_sets):\n",
    "            print('Training %s, Fold %d at ' % (name, i_fold), time.time())\n",
    "            if 'LSTM' in name or 'CNN' in name:\n",
    "                model.fit(train_set, \n",
    "                          num_epochs=num_epochs, \n",
    "                          batch_size=batch_size, \n",
    "                          verbose=verbose)\n",
    "            elif 'EKF' in name:\n",
    "                model.fit(train_set)\n",
    "            else:\n",
    "                raise ValueError(\"invalid model for testing\")\n",
    "\n",
    "            model.save('%s/%s_fold%d' % (model_dir, name, i_fold)) # model_dir is a \n",
    "        print('Finished model: ', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_models(names, models, train_sets, test_sets, results_dir, top_k_goal=None):\n",
    "    for name, model in zip(names, models):\n",
    "        for i_fold, (train_set, test_set) in enumerate(zip(train_sets, test_sets)):\n",
    "            print('Loading %s, Fold %d at ' % (name, i_fold), time.time())\n",
    "            filename = '%s/%s_fold%d' % (model_dir, name, i_fold)\n",
    "            if 'EKF' in name:\n",
    "                filename += '.pkl'\n",
    "            model.load(filename)\n",
    "        \n",
    "            # Make the predictions\n",
    "            pred_dict = {}\n",
    "            for tkey, tset in zip(['train', 'test'], [train_set, test_set]):\n",
    "                print('\\tStarted prediction for tkey: ', tkey, ' at ', time.time())\n",
    "                goal_pred, goal_gt, traj_pred_dict, traj_gt = model.predict(tset) # either no goal or ground truth\n",
    "                \n",
    "                res_dict = {}\n",
    "                for res_key in ['goal_pred', 'goal_gt', 'traj_pred_dict', 'traj_gt']:\n",
    "                    res_dict[res_key] = eval(res_key)\n",
    "                pred_dict[tkey] = res_dict\n",
    "                \n",
    "                if 'EKF' in name or 'no_goal' in name or not top_k_goal:\n",
    "                    pass\n",
    "                else:\n",
    "                    _, _, traj_pred_dict_multimodal, _ = model.predict(tset, top_k_goal)\n",
    "                    res_dict['traj_pred_dict_mm'] = traj_pred_dict_multimodal\n",
    "                    \n",
    "            # Save them to file.\n",
    "            pickle.dump(pred_dict, open('%s/%s_fold%d_pred.pkl' % (results_dir, name, i_fold), 'wb'))\n",
    "        print('Finished model: ', name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Building, Model Selection, and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tffiles_to_process = glob.glob(tfrecord_search_str)\n",
    "train_sets, test_sets = build_train_test_splits(tffiles_to_process, num_tf_folds=5) # k-fold cross validation sets\n",
    "\n",
    "# Build the model bank.  If GPU memory is problematic, can generate models in a loop instead.\n",
    "models = []\n",
    "names = []\n",
    "\n",
    "# Common LSTM/CNN+LSTM parameters\n",
    "# TODO: Hard coded for now, else need to read the tfrecord and extract it from there.\n",
    "# This is tuned for our dataset.\n",
    "history_shape       = (5, 3)         # pose history: history horizon of 5, pose dim of 3\n",
    "image_input_shape   = (5,325,100,3)  # image history: history horizon of 5, image is 325x100x3\n",
    "goal_position_shape = (32*3,)         # occupancy info: 32 spots x (x,y,is_free) flattened\n",
    "one_hot_goal_shape  = (32+1,)         # intent prediction dim: 32 spots + 1 \"undetermined\" category\n",
    "future_shape        = (20, 2)        # position future: future horizon of 20, xy position dim of 2\n",
    "\n",
    "hidden_dim = 100                     # hidden dimension for LSTM \n",
    "top_k_goal = [0,1,2]                 # specify which trajectory rollouts to predict for multimodal predictions\n",
    "                                     # (i.e. 0 = most probable intent, 1 = second-most probable intent, etc.)\n",
    "\n",
    "''' Start of models for evaluation. '''\n",
    "# EKF baseline.\n",
    "#models.append(EKF_CV_MODEL(x_init=np.zeros(5), P_init=np.eye(5), R=np.diag([1e-3]*3), dt=0.1))\n",
    "#names.append('EKF_CV')\n",
    "\n",
    "# Multimodal CNN+LSTM and CNN models.\n",
    "gamma = 1.0                  # occupancy penalty weight for intent prediction\n",
    "for beta in [0.1, 0.5, 1.0]: # max-entropy weight for intent prediction       \n",
    "    models.append(\n",
    "        CombinedCNNLSTM(history_shape,\n",
    "                     goal_position_shape,\n",
    "                     image_input_shape,\n",
    "                     one_hot_goal_shape,\n",
    "                     future_shape,\n",
    "                     hidden_dim,\n",
    "                     beta=beta,\n",
    "                     gamma=gamma,\n",
    "                     use_goal_info=True))\n",
    "    names.append('CNN_b%.3f_g%.3f' % (beta,gamma))\n",
    "\n",
    "    models.append(\n",
    "            CombinedLSTM(history_shape,\n",
    "                         goal_position_shape,\n",
    "                         one_hot_goal_shape,\n",
    "                         future_shape,\n",
    "                         hidden_dim,\n",
    "                         beta=beta,\n",
    "                         gamma=gamma,\n",
    "                         use_goal_info=True)\n",
    "        )\n",
    "    names.append('LSTM_b%.3f_g%.3f' % (beta,gamma))\n",
    "\n",
    "# Unimodal variants of CNN+LSTM/LSTM with no intent label\n",
    "# provided for trajectory regression (only history features).\n",
    "models.append(\n",
    "        CombinedCNNLSTM(history_shape,\n",
    "                     goal_position_shape,\n",
    "                     image_input_shape,\n",
    "                     one_hot_goal_shape,\n",
    "                     future_shape,\n",
    "                     hidden_dim,\n",
    "                     beta=beta,\n",
    "                     gamma=gamma,\n",
    "                     use_goal_info=False))\n",
    "names.append('CNN_no_goal')\n",
    "\n",
    "models.append(\n",
    "        CombinedLSTM(history_shape,\n",
    "                     goal_position_shape,\n",
    "                     one_hot_goal_shape,\n",
    "                     future_shape,\n",
    "                     hidden_dim,\n",
    "                     beta=beta,\n",
    "                     gamma=gamma,\n",
    "                     use_goal_info=False))\n",
    "names.append('LSTM_no_goal')\n",
    "''' End of models for evaluation. '''\n",
    "\n",
    "if MODE is 'TRAIN':\n",
    "    train_models(names, models, train_sets, model_dir, num_epochs=200, batch_size=32, verbose=1)\n",
    "elif MODE is 'PREDICT':\n",
    "    predict_models(names, models, train_sets, test_sets, results_dir, top_k_goal=top_k_goal)\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode: \", MODE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
