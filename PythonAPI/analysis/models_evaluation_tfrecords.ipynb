{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-weight:bold\"> Evaluates predictions, computes metrics, and plots results. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"      # choose which GPU to run on.\n",
    "\n",
    "import matplotlib\n",
    "font = {'weight' : 'normal',\n",
    "        'size'   : 14}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# Trajectory Regression Metrics:\n",
    "# min_dist_by_timestep: returns the min 2-norm error by timestep across all multimodal preds\n",
    "# weighted_dist_by_timestep: returns the avg 2-norm error by timestep across all multimodal preds\n",
    "# dist_by_timestep: returns the 2-norm error by timestep for unimodal prediction\n",
    "from evaluation_metrics import min_dist_by_timestep, weighted_dist_by_timestep, dist_by_timestep\n",
    "\n",
    "# Intent Classification Metrics \n",
    "# top_k_accuracy: returns the avg. top-k-accuracy for intent prediction\n",
    "# mean_entropy: returns the avg. entropy of the intent prediction distribution\n",
    "from evaluation_metrics import top_k_accuracy, mean_entropy                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set notebook parameters (change each time you run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'COMPUTE' \n",
    "# 'COMPUTE'   : computes metric results and saves to eval_metrics_file\n",
    "# 'LOAD'      : load precomputed metric results from eval_metrics_file\n",
    "\n",
    "# Results directory where predictions have been saved.\n",
    "results_dir = './results'\n",
    "\n",
    "# Directory to save summary figures of the evaluation metrics.\n",
    "figs_dir = results_dir + '/figs'\n",
    "\n",
    "# Name of pickle file where to save evaluation metrics.\n",
    "eval_metrics_file = results_dir + '/eval_metrics.pkl'\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "if not os.path.exists(figs_dir):\n",
    "    os.makedirs(figs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_results_dict(results_dir):\n",
    "    pred_files = glob.glob(results_dir + '/*pred.pkl')  # files where predictions are saved\n",
    "    result_dict = {}                                     # final dictionary returned with metrics\n",
    "    \n",
    "    for file in pred_files:\n",
    "        name = file.split('/')[-1].split('_fold')[0] # model name (e.g. EKF_CV, CNN_b0.100_g1.000, etc.)\n",
    "\n",
    "        # Make a new dictionary entry if required.\n",
    "        if name not in result_dict.keys():\n",
    "            metric_dict = {}\n",
    "            # Common metric information for every model.\n",
    "            metric_fields = ['N_instances', 'goal_top_1_acc', 'goal_top_3_acc', 'goal_top_5_acc', 'goal_entropy']\n",
    "\n",
    "            if 'EKF' in name or 'no_goal' in name:\n",
    "                metric_fields.append('traj_dist_vs_N') # unimodal, intent-agnostic prediction\n",
    "            else:\n",
    "                metric_fields.append('gtraj_dist_vs_N') # multimodal model but using ground truth intent label (1 mode)\n",
    "                metric_fields.append('wtraj_dist_vs_N') # multimodal model and computing weighted distance error over top-n modes\n",
    "                metric_fields.append('mtraj_dist_vs_N') # multimodal model and computing min distance error over top-n modes\n",
    "                metric_fields.append('min_ade')         # multimodal model and computing min average displacement error\n",
    "            # Assemble sub dictionary and add to overall results_dict for this model.\n",
    "            for key in ['train', 'test']:\n",
    "                metric_dict[key] = {}\n",
    "                for field in metric_fields:\n",
    "                    metric_dict[key][field] = []\n",
    "            result_dict[name] = metric_dict\n",
    "\n",
    "        # Compute metrics for this model and fold.  Add to result_dict.\n",
    "        preds = pickle.load(open(file, 'rb'))\n",
    "        for tkey in ['train', 'test']:\n",
    "            goal_pred = preds[tkey]['goal_pred']\n",
    "            goal_gt   = preds[tkey]['goal_gt']\n",
    "            traj_pred_dict = preds[tkey]['traj_pred_dict']\n",
    "            traj_gt = preds[tkey]['traj_gt']\n",
    "\n",
    "            # Intent Prediction Metrics\n",
    "            t1 = top_k_accuracy(goal_pred, goal_gt, k=1)\n",
    "            t3 = top_k_accuracy(goal_pred, goal_gt, k=3)\n",
    "            t5 = top_k_accuracy(goal_pred, goal_gt, k=5)\n",
    "            ment = mean_entropy(goal_pred)\n",
    "\n",
    "            result_dict[name][tkey]['N_instances'].append(goal_pred.shape[0])\n",
    "            result_dict[name][tkey]['goal_top_1_acc'].append(t1)\n",
    "            result_dict[name][tkey]['goal_top_3_acc'].append(t3)\n",
    "            result_dict[name][tkey]['goal_top_5_acc'].append(t5)\n",
    "            result_dict[name][tkey]['goal_entropy'].append(ment)\n",
    "\n",
    "            if 'EKF' in name or 'no_goal' in name:\n",
    "                # Unimodal, intent-agnostic prediction\n",
    "                meand, mind, maxd = dist_by_timestep(traj_pred_dict, traj_gt[:,:,:2])\n",
    "                result_dict[name][tkey]['traj_dist_vs_N'].append(meand)\n",
    "            else:            \n",
    "                # Ground truth intent input used for regression. Unimodal but intent-conditioned.\n",
    "                meand, mind, maxd = dist_by_timestep(traj_pred_dict, traj_gt[:,:,:2])\n",
    "                result_dict[name][tkey]['gtraj_dist_vs_N'].append(meand)\n",
    "\n",
    "                # Multimodal predictions and top-k intent predictions used for regression.\n",
    "                traj_pred_dict_multimodal = preds[tkey]['traj_pred_dict_mm']\n",
    "                wmeand = weighted_dist_by_timestep(goal_pred, traj_pred_dict_multimodal, traj_gt[:,:,:2])\n",
    "                mmeand, mmade = min_dist_by_timestep(traj_pred_dict_multimodal, traj_gt[:,:,:2])\n",
    "                result_dict[name][tkey]['wtraj_dist_vs_N'].append(wmeand)\n",
    "                result_dict[name][tkey]['mtraj_dist_vs_N'].append(mmeand)\n",
    "                result_dict[name][tkey]['min_ade'].append(mmade)\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE is 'COMPUTE':\n",
    "    model_res_dict = compute_metric_results_dict(results_dir)\n",
    "    pickle.dump(model_res_dict, open(eval_metrics_file, 'wb'))\n",
    "elif MODE is 'LOAD':\n",
    "    model_res_dict = pickle.load(open(eval_metrics_file, 'rb'))\n",
    "[print(k) for k in sorted(model_res_dict.keys())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 1: Unimodal trajectory evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualizes trajectory distance error by timestep for EKF, LSTM no/gt intent, CNN no/gt intent variants.\n",
    "# gt_intent generated by passing ground truth intent label to trajectory submodule of a multimodal LSTM/CNN-LSTM.\n",
    "\n",
    "# Load data to put into a Pandas dataframe.\n",
    "data_list = []\n",
    "for model in sorted(model_res_dict.keys()):\n",
    "    for split in model_res_dict[model].keys(): # split = 'train' or 'test'\n",
    "        if 'no_goal' in model:\n",
    "            # Intent-agnostic trajectory prediction with CNN/LSTM.\n",
    "            name = model\n",
    "            name = name.replace('goal', 'intent') # for plots, want name to say 'no_intent'\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "        elif 'EKF' in model:\n",
    "            # EKF baseline trajectory prediction.\n",
    "            name = model \n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "        elif 'b1.000_g1.000' in model:\n",
    "            # Intent-conditioned trajectory prediction with CNN/LSTM.\n",
    "            # This is a hack to choose one of the multimodal models and evaluate on\n",
    "            # ground truth label for intent input.  May need to change key in general\n",
    "            # if different beta/gammas are used.\n",
    "            name = model.split('b1.000_g1.000')[0] + 'gt_intent'\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['gtraj_dist_vs_N']\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "        for i_fold, td in enumerate(traj_dist_vs_N):\n",
    "            for j_timestep, dist_timestep in enumerate(td):\n",
    "                # j_timestep is 0-indexed but should be 1-indexed in plotting.\n",
    "                data_list.append([name, split, i_fold, j_timestep+1, dist_timestep])\n",
    "\n",
    "# Assemble dataframes and split into train/test results.            \n",
    "traj_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Timestep', 'Distance Error'],dtype=float)\n",
    "traj_df_train = traj_df[traj_df.Split == 'train']\n",
    "traj_df_test  = traj_df[traj_df.Split == 'test']\n",
    "\n",
    "# TODO: x and y ticks manually adjusted below based on data range.  \n",
    "# Can use data limits to automate in future.\n",
    "for split, df in zip(['TRAIN', 'TEST'], [traj_df_train, traj_df_test]):\n",
    "    print('='*50, split, '='*50)\n",
    "    \n",
    "    # All models on one plot for the given split.\n",
    "    f1 = plt.figure(dpi=200)\n",
    "    ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=df)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Distance Error (m)')\n",
    "    plt.xticks(np.arange(0, 21, step=2))      \n",
    "    plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "    plt.draw(); plt.pause(0.01)\n",
    "    f1.savefig('%s/traj_info_level_all_%s.svg' % (figs_dir, split), bbox_inches='tight')\n",
    "    \n",
    "    # All \"no intent\" models + EKF for the given split.\n",
    "    f2 = plt.figure(dpi=200)\n",
    "    ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=df[~df.Model.str.contains('gt')])\n",
    "    plt.legend()\n",
    "    plt.ylabel('Distance Error (m)')\n",
    "    plt.xticks(np.arange(0, 21, step=2))\n",
    "    plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "    plt.draw(); plt.pause(0.01)\n",
    "    f2.savefig('%s/traj_info_level_ng_%s.svg' % (figs_dir, split), bbox_inches='tight')\n",
    "    \n",
    "    # All \"ground truth intent\" models + EKF for the given split.\n",
    "    f3 = plt.figure(dpi=200)\n",
    "    ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=df[~df.Model.str.contains('no')])\n",
    "    plt.legend()\n",
    "    plt.ylabel('Distance Error (m)')\n",
    "    plt.xticks(np.arange(0, 21, step=2))\n",
    "    plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "    plt.draw(); plt.pause(0.01)\n",
    "    f3.savefig('%s/traj_info_level_gt_%s.svg' % (figs_dir, split), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 2: Multimodal trajectory evaluation using minimum distance to trajectory metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizes trajectory distance error by timestep for the following models:\n",
    "# LSTM multimodal, LSTM no intent, CNN multimodal, and CNN no intent variants.\n",
    "# gt_intent generated by passing ground truth intent label to trajectory submodule of a multimodal LSTM/CNN-LSTM.\n",
    "\n",
    "# Load data to put into a Pandas dataframe.\n",
    "data_list = []\n",
    "for model in sorted(model_res_dict.keys()):\n",
    "    for split in model_res_dict[model].keys(): # split = 'train' or 'test'\n",
    "        if 'no_goal' in model:\n",
    "            # Intent-agnostic trajectory prediction with CNN/LSTM.\n",
    "            name = model\n",
    "            name = name.replace('goal', 'intent') # for plots, want name to say 'no_intent'\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['traj_dist_vs_N']\n",
    "        elif 'EKF' in model:\n",
    "            continue\n",
    "        else:\n",
    "            # Use the min_dist_by_timestep metric, which finds the dist_by_timestep\n",
    "            # to the trajectory that is the argmin entry to the min average displacement\n",
    "            # error metric (e.g. used by Waymo in the MultiPath paper).\n",
    "            name = model.split('_g')[0]\n",
    "            name = name.replace('_', '\\_')\n",
    "            name = name.replace('b', '\\\\beta')\n",
    "            name = r'$%s$' % name\n",
    "            traj_dist_vs_N = model_res_dict[model][split]['mtraj_dist_vs_N']\n",
    "    \n",
    "        for i_fold, td in enumerate(traj_dist_vs_N):\n",
    "            for j_timestep, dist_timestep in enumerate(td):\n",
    "                # j_timestep is 0-indexed but should be 1-indexed in plotting.\n",
    "                data_list.append([name, split, i_fold, j_timestep+1, dist_timestep])\n",
    "\n",
    "# Assemble dataframes and split into train/test results.            \n",
    "traj_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Timestep', 'Distance Error'],dtype=float)\n",
    "traj_df_train = traj_df[traj_df.Split == 'train']\n",
    "traj_df_test  = traj_df[traj_df.Split == 'test']\n",
    "\n",
    "# TODO: x and y ticks manually adjusted below based on data range.  \n",
    "# Can use data limits to automate in future.\n",
    "for split, df in zip(['TRAIN', 'TEST'], [traj_df_train, traj_df_test]):\n",
    "    print('='*50, split, '='*50)\n",
    "    \n",
    "    # All models on one plot for the given split.\n",
    "    f1 = plt.figure(dpi=200)\n",
    "    ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=df)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.ylabel('Distance Error (m)')\n",
    "    plt.xticks(np.arange(0, 21, step=2))      \n",
    "    plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "    #plt.minorticks_on()\n",
    "    #plt.grid(which='minor', linestyle='-', linewidth=2)\n",
    "    plt.draw(); plt.pause(0.01)\n",
    "    f1.savefig('%s/traj_multimodal_mdist_all_%s.svg' % (figs_dir, split), bbox_inches='tight')\n",
    "    \n",
    "    # CNN models only for the given split.\n",
    "    f2 = plt.figure(dpi=200)\n",
    "    with sns.color_palette('bright'):\n",
    "        ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=df[df.Model.str.contains('CNN')])\n",
    "        plt.legend()\n",
    "        plt.ylabel('Distance Error (m)')\n",
    "        plt.xticks(np.arange(0, 21, step=2))\n",
    "        plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "        #plt.minorticks_on()\n",
    "        #plt.grid(which='minor', linestyle='-', linewidth=2)\n",
    "        plt.draw(); plt.pause(0.01)\n",
    "    f2.savefig('%s/traj_multimodal_mdist_cnn_%s.svg' % (figs_dir, split), bbox_inches='tight')\n",
    "    \n",
    "    # LSTM models only for the given split.\n",
    "    f3 = plt.figure(dpi=200)\n",
    "    with sns.color_palette('deep'):\n",
    "        ax = sns.lineplot(x=\"Timestep\", y=\"Distance Error\", hue=\"Model\", data=df[df.Model.str.contains('LSTM')])\n",
    "        plt.legend()\n",
    "        plt.ylabel('Distance Error (m)')\n",
    "        plt.xticks(np.arange(0, 21, step=2))\n",
    "        plt.yticks(np.arange(0, 1.51, step=0.25))\n",
    "        #plt.minorticks_on()\n",
    "        #plt.grid(which='minor', linestyle='-', linewidth=2)\n",
    "        plt.draw(); plt.pause(0.01)\n",
    "    f3.savefig('%s/traj_multimodal_mdist_lstm_%s.svg' % (figs_dir, split), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 3: Multimodal trajectory evaluation using minimum average displacement error (min ADE) metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualizes minimum average displacement (Waymo MultiPath paper) for the following models:\n",
    "# LSTM multimodal, LSTM no intent, CNN multimodal, and CNN no intent variants.\n",
    "# gt_intent generated by passing ground truth intent label to trajectory submodule of a multimodal LSTM/CNN-LSTM.\n",
    "\n",
    "# Load data to put into a Pandas dataframe.\n",
    "data_list = []\n",
    "for model in sorted(model_res_dict.keys()):\n",
    "    for split in model_res_dict[model].keys(): # split = 'train' or 'test'\n",
    "        if 'no_goal' in model:\n",
    "            # Intent-agnostic trajectory prediction with CNN/LSTM.\n",
    "            name = model\n",
    "            name = name.replace('goal', 'intent') # for plots, want name to say 'no_intent'\n",
    "            ades = [np.mean(x) for x in model_res_dict[model][split]['traj_dist_vs_N']]\n",
    "        elif 'EKF' in model:\n",
    "            name = model\n",
    "            ades = [np.mean(x) for x in model_res_dict[model][split]['traj_dist_vs_N']]\n",
    "        else:\n",
    "            # Use the min_dist_by_timestep metric, which finds the dist_by_timestep\n",
    "            # to the trajectory that is the argmin entry to the min average displacement\n",
    "            # error metric (e.g. used by Waymo in the MultiPath paper).\n",
    "            name = model.split('_g')[0]\n",
    "            name = name.replace('_', '\\_')\n",
    "            name = name.replace('b', '\\\\beta')\n",
    "            name = r'$%s$' % name\n",
    "            ades = model_res_dict[model][split]['min_ade']\n",
    "        \n",
    "        for i_fold, ade_fold in enumerate(ades):\n",
    "            data_list.append([name, split, i_fold, ade_fold])\n",
    "\n",
    "# Assemble dataframes and split into train/test results.            \n",
    "traj_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'Min ADE'],dtype=float)\n",
    "traj_df_train = traj_df[traj_df.Split == 'train']\n",
    "traj_df_test  = traj_df[traj_df.Split == 'test']\n",
    "\n",
    "\n",
    "# TODO: x and y ticks manually adjusted below based on data range.  \n",
    "# Can use data limits to automate in future.\n",
    "for split, df in zip(['TRAIN', 'TEST'], [traj_df_train, traj_df_test]):\n",
    "    print('='*50, split, '='*50)\n",
    "    from IPython.display import Latex\n",
    "    \n",
    "    print( df.groupby(\"Model\")[\"Min ADE\"].agg([np.mean, np.std]).sort_values(by='mean') )\n",
    "    \n",
    "#     # All models on one plot for the given split.\n",
    "#     f1 = plt.figure(dpi=200)\n",
    "#     ax = sns.barplot(x=\"Model\", y=\"Min ADE\", data=df)\n",
    "#     plt.ylabel('Min Average Distance Error (m)')\n",
    "#     print([label for label in ax.get_xticklabels()])\n",
    "#     ax.set_xticklabels(['']*len(ax.get_xticklabels()))\n",
    "#     #plt.xticks(np.arange(0, 21, step=2))      \n",
    "#     plt.yticks(np.arange(0, 1.01, step=0.25))\n",
    "#     plt.draw(); plt.pause(0.01)\n",
    "#     #f1.savefig('%s/traj_multimodal_min_ade_%s.svg' % (figs_dir, split), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot 4: Intent Prediction Evaluation using Top-k accuracy (also called Top-n in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to put into a Pandas dataframe.\n",
    "data_list = []\n",
    "model_list = sorted(model_res_dict.keys())\n",
    "model_list.remove('EKF_CV')\n",
    "model_list.insert(0, 'EKF_CV') # put EKF result first in the barplot\n",
    "\n",
    "for model in model_list:\n",
    "    if 'no_goal' in model:\n",
    "        continue\n",
    "    if 'EKF' in model:\n",
    "        name = model\n",
    "    else:\n",
    "        name = model.split('_g')[0]\n",
    "        name = name.replace('_', '\\_')\n",
    "        name = name.replace('b', '\\\\beta')\n",
    "        name = r'$%s$' % name\n",
    "        \n",
    "    for split in model_res_dict[model].keys():\n",
    "        goal_top_1_acc = model_res_dict[model][split]['goal_top_1_acc']\n",
    "        goal_top_3_acc = model_res_dict[model][split]['goal_top_3_acc']\n",
    "        goal_top_5_acc = model_res_dict[model][split]['goal_top_5_acc']\n",
    "        \n",
    "        for i_fold, (t1, t3, t5) in enumerate(zip(goal_top_1_acc, \n",
    "                                                  goal_top_3_acc,\n",
    "                                                  goal_top_5_acc)):\n",
    "            data_list.append([name, split, i_fold, 1, t1])\n",
    "            data_list.append([name, split, i_fold, 3, t3])\n",
    "            data_list.append([name, split, i_fold, 5, t5])\n",
    "                        \n",
    "goal_df = pd.DataFrame(data_list, columns=['Model', 'Split', 'Fold', 'k', 'Accuracy'],dtype=float)\n",
    "goal_train_df = goal_df[goal_df.Split == 'train']\n",
    "goal_test_df = goal_df[goal_df.Split == 'test']\n",
    "\n",
    "# Top-k Accuracy across all models.\n",
    "for fold, df in zip(['TRAIN', 'TEST'], [goal_train_df, goal_test_df]):\n",
    "    print('='*50, fold, '='*50)\n",
    "    f = plt.figure(dpi=200)\n",
    "    ax = sns.barplot(x='k', y='Accuracy', hue='Model', data=df)\n",
    "    plt.xlabel('n')\n",
    "    plt.ylabel('Top-n Accuracy')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()  \n",
    "    \n",
    "    plt.draw(); plt.pause(0.01)\n",
    "    f.savefig('%s/intent_acc_%s.svg' % (figs_dir, fold), bbox_inches='tight')\n",
    "    \n",
    "    print('TOP 1')\n",
    "    print( df[df.k == 1.0].groupby(\"Model\")[\"Accuracy\"].agg([np.mean, np.std]) )\n",
    "    \n",
    "    print('TOP 3')\n",
    "    print( df[df.k == 3.0].groupby(\"Model\")[\"Accuracy\"].agg([np.mean, np.std]) )\n",
    "    \n",
    "    print('TOP 5')\n",
    "    print( df[df.k == 5.0].groupby(\"Model\")[\"Accuracy\"].agg([np.mean, np.std]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
