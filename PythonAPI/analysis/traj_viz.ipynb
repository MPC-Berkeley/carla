{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses trained models and makes plots/videos of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from pkl_reader import *\n",
    "from lstm_impl import CombinedLSTM\n",
    "from kf_impl import EKF_CV_MODEL\n",
    "from cnn_lstm_impl import CombinedCNNLSTM\n",
    "from utils import sup_plot, extract_data, get_parking_lot_image_hist, generate_movie\n",
    "\n",
    "from tfrecord_utils import write_tfrecord\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import traceback\n",
    "\n",
    "from evaluation_metrics import min_dist_by_timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the prediction model and load the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "\n",
    "history_shape       = (5, 3)         # pose history: history horizon of 5, pose dim of 3\n",
    "image_input_shape   = (5,325,100,3)  # image history: history horizon of 5, image is 325x100x3\n",
    "goal_position_shape = (32*3,)         # occupancy info: 32 spots x (x,y,is_free) flattened\n",
    "one_hot_goal_shape  = (32+1,)         # intent prediction dim: 32 spots + 1 \"undetermined\" category\n",
    "future_shape        = (20, 2)        # position future: future horizon of 20, xy position dim of 2\n",
    "\n",
    "hidden_dim = 100                     # hidden dimension for LSTM \n",
    "top_k_goal = [0,1,2]                 # specify which trajectory rollouts to predict for multimodal predictions\n",
    "                                     # (i.e. 0 = most probable intent, 1 = second-most probable intent, etc.)\n",
    "\n",
    "gamma = 1.0\n",
    "beta  = 1.0\n",
    "\n",
    "models = {}\n",
    "\n",
    "for model_name in [\"EKF_CV\", \"LSTM\", \"CNN\"]:\n",
    "    if model_name == \"EKF_CV\":\n",
    "        model = EKF_CV_MODEL(x_init=np.zeros(5), P_init=np.eye(5), R=np.diag([1e-3]*3), dt=0.1)\n",
    "        h5files_to_process = glob.glob('./models/EKF*.pkl')\n",
    "        filename = \"./models/EKF_CV_fold4.pkl\"\n",
    "    elif model_name == \"LSTM\":    \n",
    "        model = CombinedLSTM(history_shape,\n",
    "                             goal_position_shape,\n",
    "                             one_hot_goal_shape,\n",
    "                             future_shape,\n",
    "                             hidden_dim,\n",
    "                             beta=beta,\n",
    "                             gamma=gamma,\n",
    "                             use_goal_info=True)\n",
    "        h5files_to_process = glob.glob('./models/LSTM*.h5')\n",
    "        filename = \"./models/LSTM_b1.000_g1.000_fold4\"\n",
    "    elif model_name == \"CNN\":\n",
    "        model = CombinedCNNLSTM(history_shape,\n",
    "                                 goal_position_shape,\n",
    "                                 image_input_shape,\n",
    "                                 one_hot_goal_shape,\n",
    "                                 future_shape,\n",
    "                                 hidden_dim,\n",
    "                                 beta=beta,\n",
    "                                 gamma=gamma,\n",
    "                                 use_goal_info=True)\n",
    "        h5files_to_process = glob.glob('./models/CNN*.h5')\n",
    "        filename = \"./models/CNN_b1.000_g1.000_fold4\"\n",
    "    \n",
    "    print(model_name + ': Found %d model files: %s' % (len(h5files_to_process), h5files_to_process))\n",
    "    model.load(filename)\n",
    "    models[model_name] = model\n",
    "    print(model_name + ': Load Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the pkl into tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_ext = 'pkl'\n",
    "file_prefix = '../examples/bags/'\n",
    "search_str = file_prefix + '*.' + save_ext \n",
    "files_to_process = glob.glob(search_str)\n",
    "print('Found %d files to read: %s' % (len(files_to_process), files_to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl2tf(file):\n",
    "    prune_start=True          # remove stationary portion of ego's trajectory at the start\n",
    "    prune_end=True            # remove stationary portion of ego's trajectory at the end\n",
    "    min_vel_thresh=0.01       # velocity threshold (m/s) above which ego is considered moving\n",
    "    exclude_collisions=True  # return an empty trajectory if there was a collision\n",
    "\n",
    "    Nhist=5          # number of timesteps of motion history to predict with\n",
    "    Npred=20         # number of timesteps of prediction horizon\n",
    "    Nskip=5          # \"stride\" for sliding window of snippet selection\n",
    "    dt=0.1           # discretization (s) of full ego trajectory corresponding to N* above\n",
    "    ego_trans = True # whether or not to represent trajectory snippets in the ego frame\n",
    "                     # if False, use the global map frame for all snippets\n",
    "    \n",
    "    \n",
    "    # full dataset for all files_to_process\\\n",
    "    save_ext = 'pkl'\n",
    "    features_combined = []\n",
    "    features_global_combined = []\n",
    "    labels_combined = []\n",
    "    goal_snpts_combined = []\n",
    "    static_objs_combined = []\n",
    "\n",
    "    parking_lot = None\n",
    "    ego_dims    = None\n",
    "    \n",
    "    if save_ext == 'pkl':\n",
    "        res_dict = pickle.load(open(file,'rb'))\n",
    "    else:\n",
    "        raise NotImplemented('Invalid Extension')\n",
    "    \n",
    "    goals = extract_goals(res_dict)\n",
    "    parking_lot = res_dict['parking_lot']\n",
    "    ego_dims = res_dict['ego_dimensions']\n",
    "    \n",
    "    try:\n",
    "        assert goals.shape[0] == 32, \"Invalid goal shape.\"\n",
    "        assert len(res_dict['vehicle_object_lists'][0]) == 56, \"Wrong number of static vehicles.\"\n",
    "        \n",
    "        # parse one demonstration\n",
    "        ego_trajectory, start_ind, switch_ind, end_ind, goal_ind = \\\n",
    "             extract_full_trajectory(res_dict, goals, prune_start, prune_end, \\\n",
    "                                     min_vel_thresh, exclude_collisions)\n",
    "        \n",
    "        features, features_global, labels, labels_global, goal_snpts = \\\n",
    "            get_ego_trajectory_prediction_snippets(ego_trajectory, start_ind, switch_ind, end_ind, goal_ind, \\\n",
    "                                           goals, Nhist, Npred, Nskip, dt, ego_frame=ego_trans)\n",
    "        \n",
    "        features_combined.extend(features)\n",
    "        features_global_combined.extend(features_global)\n",
    "        labels_combined.extend(labels)\n",
    "        goal_snpts_combined.extend(goal_snpts)\n",
    "        \n",
    "        static_object_list = res_dict['static_object_list']\n",
    "        for i in range(len(features)):\n",
    "            static_objs_combined.append(static_object_list)\n",
    "    except Exception as e:\n",
    "        print(file, e)\n",
    "        traceback.print_exc()\n",
    "        return None, None, None, None, None, None\n",
    "\n",
    "    num_features = len(features_global_combined)\n",
    "\n",
    "    img_hists_batch = np.array(\n",
    "        [get_parking_lot_image_hist(parking_lot, \n",
    "                                    static_objs_combined[k], \n",
    "                                    features_global_combined[k], \n",
    "                                    ego_dims, resize_factor=0.5) for k in range(len(static_objs_combined))])\n",
    "    \n",
    "    file_location = file[:-4] + '.tfrecord'\n",
    "\n",
    "    print('Saving to ', file_location)\n",
    "\n",
    "    write_tfrecord(features_combined,\n",
    "                   img_hists_batch,\n",
    "                   labels_combined, \n",
    "                   goal_snpts_combined,\n",
    "                   file_location, {})\n",
    "    \n",
    "    return parking_lot, static_object_list, features_global, labels_global, goal_snpts, ego_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pkl2tf_info = []\n",
    "\n",
    "for filenum in range(len(files_to_process)):\n",
    "    print(\"%d/%d Processing file:\" % (filenum, len(files_to_process)), files_to_process[filenum])\n",
    "    parking_lot, static_object_list, features_global, labels_global, goal_snpts, ego_trajectory = pkl2tf(files_to_process[filenum])\n",
    "    \n",
    "    if parking_lot is not None:\n",
    "        info = {}\n",
    "        info[\"parking_lot\"] = parking_lot\n",
    "        info[\"static_object_list\"] = static_object_list\n",
    "        info[\"features_global\"] = features_global\n",
    "        info[\"labels_global\"] = labels_global\n",
    "        info[\"goal_snpts\"] = goal_snpts\n",
    "        info[\"ego_trajectory\"] = ego_trajectory\n",
    "        pkl2tf_info.append(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pkl2tf_info into file\n",
    "fname = \"./figures/saved_stat/all_pkl2tf_info.pkl\"\n",
    "pickle.dump(pkl2tf_info, open(fname, 'wb'))\n",
    "print('Saved all pkl2tf_info into:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the tfrecords are already converted, load the info dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pkl2tf_info from file\n",
    "fname = \"./figures/saved_stat/all_pkl2tf_info.pkl\"\n",
    "pkl2tf_info = pickle.load(open(fname,'rb'))\n",
    "print('Loaded all pkl2tf_info from:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the demos to predict and get statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the predict data\n",
    "tf_to_process = glob.glob('../examples/bags/*.tfrecord')\n",
    "tf_to_process.sort()\n",
    "print('Found %d tfrecord files: %s' % (len(tf_to_process), tf_to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To store and compare the trajectories with min and max ade\n",
    "min_traj_dict = {\"case_name\": None, \"filenum\": -1, \"value\":  np.inf}\n",
    "max_traj_dict = {\"case_name\": None, \"filenum\": -1, \"value\": -np.inf}\n",
    "min_mmade = {\"EKF_CV\": min_traj_dict.copy(), \"LSTM\": min_traj_dict.copy(), \"CNN\": min_traj_dict.copy()}\n",
    "max_mmade = {\"EKF_CV\": max_traj_dict.copy(), \"LSTM\": max_traj_dict.copy(), \"CNN\": max_traj_dict.copy()}\n",
    "\n",
    "all_mmade = {\"EKF_CV\": np.zeros(len(tf_to_process)), \n",
    "             \"LSTM\":   np.zeros(len(tf_to_process)),\n",
    "             \"CNN\":    np.zeros(len(tf_to_process))}\n",
    "save_ext = 'png'\n",
    "\n",
    "# Process all files and get the statistics\n",
    "for filenum in range(len(tf_to_process)):\n",
    "    print(\"%d/%d:\" % (filenum, len(tf_to_process)), \"=== Calculating statistics for tfrecord: \" + tf_to_process[filenum] + \" =====\")\n",
    "    case_name = \"_\".join(tf_to_process[filenum].split(\"_\")[1:4])\n",
    "    extreme_case = False\n",
    "    \n",
    "    top_k_goal = [0,1,2]\n",
    "    for model_name in [\"EKF_CV\", \"LSTM\", \"CNN\"]:\n",
    "        if model_name == \"EKF_CV\":\n",
    "            goal_pred, goal_gt, traj_pred_dict, traj_gt = models[model_name].predict(tf_to_process[filenum])\n",
    "        else:\n",
    "            goal_pred, goal_gt, traj_pred_dict, traj_gt = models[model_name].predict(tf_to_process[filenum], top_k_goal)\n",
    "        \n",
    "        instance_name = model_name + \"_\" + case_name\n",
    "        \n",
    "        _, mmade = min_dist_by_timestep(traj_pred_dict, traj_gt[:,:,:2])\n",
    "        \n",
    "        all_mmade[model_name][filenum] = mmade\n",
    "        \n",
    "        # If this trajectory is an extreme case for any model, set the flag to be true to keep it\n",
    "        if mmade > max_mmade[model_name][\"value\"]:\n",
    "            max_mmade[model_name][\"value\"]     = mmade\n",
    "            max_mmade[model_name][\"filenum\"]   = filenum\n",
    "            max_mmade[model_name][\"case_name\"] = case_name\n",
    "            \n",
    "        if mmade < min_mmade[model_name][\"value\"]:\n",
    "            min_mmade[model_name][\"value\"]     = mmade\n",
    "            min_mmade[model_name][\"filenum\"]   = filenum\n",
    "            min_mmade[model_name][\"case_name\"] = case_name\n",
    "\n",
    "\n",
    "print(\"Min mmade for each model:\", min_mmade)\n",
    "print(\"Max mmade for each model:\", max_mmade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the statistics into file\n",
    "fname = \"./figures/saved_stat/all_mmades.pkl\"\n",
    "pickle.dump(all_mmade, open(fname, 'wb'))\n",
    "print('Saved all mmades into:', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get generate movies based on statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenums_for_movie = set()\n",
    "for model_name in [\"EKF_CV\", \"LSTM\", \"CNN\"]:\n",
    "    filenums_for_movie.add(max_mmade[model_name][\"filenum\"])\n",
    "    filenums_for_movie.add(min_mmade[model_name][\"filenum\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"The trajs to generate movie are:\", [tf_to_process[filenum] for filenum in filenums_for_movie])\n",
    "            \n",
    "for filenum in filenums_for_movie:\n",
    "    print(\"\\n=== Generating video for tfrecord: \" + tf_to_process[filenum] + \" =====\")\n",
    "    case_name = \"_\".join(tf_to_process[filenum].split(\"_\")[1:4])\n",
    "#     extreme_case = False\n",
    "    \n",
    "    parking_lot        = pkl2tf_info[filenum][\"parking_lot\"]\n",
    "    static_object_list = pkl2tf_info[filenum][\"static_object_list\"]\n",
    "    features_global    = pkl2tf_info[filenum][\"features_global\"]\n",
    "    labels_global      = pkl2tf_info[filenum][\"labels_global\"]\n",
    "    goal_snpts         = pkl2tf_info[filenum][\"goal_snpts\"]\n",
    "    ego_trajectory     = pkl2tf_info[filenum][\"ego_trajectory\"]\n",
    "    \n",
    "    top_k_goal = [0,1,2]\n",
    "    for model_name in [\"EKF_CV\", \"LSTM\", \"CNN\"]:\n",
    "        if model_name == \"EKF_CV\":\n",
    "            goal_pred, goal_gt, traj_pred_dict, traj_gt = models[model_name].predict(tf_to_process[filenum])\n",
    "        else:\n",
    "            goal_pred, goal_gt, traj_pred_dict, traj_gt = models[model_name].predict(tf_to_process[filenum], top_k_goal)\n",
    "            \n",
    "        instance_name = model_name + \"_\" + case_name\n",
    "        generate_movie(instance_name, parking_lot, static_object_list, \n",
    "                       traj_pred_dict, features_global, labels_global, goal_pred, goal_gt, goal_snpts, top_k_goal, movie=False)\n",
    "    \n",
    "    files_to_process = {}\n",
    "    num_frame = 0\n",
    "    \n",
    "    for model_name in [\"EKF_CV\", \"LSTM\", \"CNN\"]:\n",
    "        file_prefix = './figures/' + model_name + \"_\" + case_name\n",
    "        search_str = file_prefix + '/*.' + save_ext\n",
    "        files_to_process[model_name] = glob.glob(search_str)\n",
    "        num_frame = len(glob.glob(search_str))\n",
    "\n",
    "    # print(files_to_process)\n",
    "    crop_points = (180, 250, 635, 1700)\n",
    "\n",
    "    directory = './figures/all_' + case_name\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    for frame_idx in range(num_frame):\n",
    "        imgs = []\n",
    "        for model_name in [\"EKF_CV\", \"LSTM\", \"CNN\"]:\n",
    "            img = Image.open(files_to_process[model_name][frame_idx])\n",
    "            img_new = img.crop(crop_points).transpose(Image.ROTATE_90)\n",
    "\n",
    "            imgs.append( img_new )\n",
    "\n",
    "        concat_size = ( imgs[0].size[0], 3 * imgs[0].size[1] )   \n",
    "\n",
    "        concat_img = Image.new('RGB', concat_size)\n",
    "\n",
    "        for idx, img in enumerate(imgs):\n",
    "            concat_img.paste(img, (0, idx*img.size[1]))\n",
    "\n",
    "        concat_img.save(directory + '/' + files_to_process[model_name][frame_idx].split(\"/\")[-1])\n",
    "\n",
    "    fps = 2\n",
    "    mv = os.system(\"ffmpeg -r {0:d} -i ./figures/all_{1:s}/frame_%03d.png -vcodec mpeg4 -y ./figures/{1:s}_movie.mp4\".format(fps, case_name) )\n",
    "    if mv == 0:\n",
    "        for model_name in [\"EKF_CV\", \"LSTM\", \"CNN\"]:\n",
    "            file_prefix = './figures/' + model_name + \"_\" + case_name\n",
    "            os.system(\"rm -rf %s\" % file_prefix)\n",
    "        print( case_name + \": Trajectory movie saved successfully.\")\n",
    "    else:\n",
    "        print( case_name + \": Meet problem saving Trajectorymovie.\")\n",
    "        \n",
    "print(\"Min mmade for each model:\", min_mmade)\n",
    "print(\"Max mmade for each model:\", max_mmade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the error histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12.8,9.6))\n",
    "for model_name in [\"EKF_CV\", \"LSTM\", \"CNN\"]:\n",
    "    plt.hist(all_mmade[model_name], 100, label=model_name, alpha=0.5)\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.title(\"Histogram of Error\")\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example traj for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting Fig.2 of the paper: shows the example trajectory\n",
    "fig = plt.figure(figsize=(2, 5), dpi=200, facecolor='w', edgecolor='k')\n",
    "ax = plt.gca()\n",
    "\n",
    "plt.rcParams['font.weight'] = 'normal'\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# Line\n",
    "for line_info in parking_lot:\n",
    "    rect = patches.Rectangle((line_info[0]-line_info[2]/2, line_info[1]-line_info[3]/2),line_info[2],line_info[3],line_info[4], facecolor='k')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "# Static objects\n",
    "for static_object in static_object_list:\n",
    "    if static_object[0] < 275 or static_object[0] > 295:\n",
    "        continue\n",
    "    rect = patches.Rectangle((static_object[0]-static_object[2]/2, static_object[1]-static_object[3]/2),static_object[2],static_object[3],static_object[4], facecolor='#C6B7B3')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "for pose in ego_trajectory:\n",
    "    \n",
    "    if pose[-1] == -1:\n",
    "        plt.plot(pose[1], pose[2], '.', markersize = 2, color = 'y')\n",
    "    else:\n",
    "        plt.plot(pose[1], pose[2], '.', markersize = 2, color = 'b')\n",
    "    \n",
    "    \n",
    "plt.xlabel('x (m)')\n",
    "plt.ylabel('y (m)')\n",
    "    \n",
    "plt.plot()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "features = pkl2tf_info[0]['features_global'][15]\n",
    "labels = pkl2tf_info[0]['labels_global'][15]\n",
    "\n",
    "Nhist = 5\n",
    "Npred = 20\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(range(Nhist), features[:,0], 'ko', markersize=10)\n",
    "plt.plot(range(Nhist, Nhist+Npred), labels[:,0], 'ro', markersize=10)\n",
    "plt.ylabel('X coordinates (m)')\n",
    "plt.xlabel('Time steps')\n",
    "plt.title('X')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(range(Nhist), features[:,1], 'ko', markersize=10)\n",
    "plt.plot(range(Nhist, Nhist+Npred), labels[:,1], 'ro', markersize=10)\n",
    "plt.ylabel('Y coordinates (m)')\n",
    "plt.xlabel('Time steps')\n",
    "plt.title('Y')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(range(Nhist), features[:,2], 'ko', markersize=10)\n",
    "plt.plot(range(Nhist, Nhist+Npred), labels[:,2], 'ro', markersize=10)\n",
    "plt.ylabel('Heading (rad)')\n",
    "plt.xlabel('Time steps')\n",
    "plt.title('Heading')\n",
    "\n",
    "font = {'weight' : 'normal',\n",
    "        'size'   : 17}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "pklfiles_to_process = glob.glob('./dataset/*.pkl')\n",
    "pklfiles_to_process.sort()\n",
    "print('Found %d pkl files: %s' % (len(pklfiles_to_process), pklfiles_to_process))\n",
    "\n",
    "file_num = 0\n",
    "\n",
    "pklfile = pklfiles_to_process[file_num]\n",
    "\n",
    "test_set  = {\"history_traj_data\" : None,\n",
    "             \"future_traj_data\"  : None,\n",
    "             \"goal_position\"     : None,\n",
    "             \"one_hot_goal\"      : None}\n",
    "test_set_kf  = {\"history_traj_data\" : None,\n",
    "             \"future_traj_data\"  : None,\n",
    "             \"goal_position\"     : None,\n",
    "             \"one_hot_goal\"      : None}\n",
    "\n",
    "test_set['history_traj_data'], test_set['future_traj_data'], test_set['goal_position'], test_set['one_hot_goal'], traj_idx = extract_data(pklfile, full_traj=True, crop_traj=True)\n",
    "test_set_kf['history_traj_data'], test_set_kf['future_traj_data'], test_set_kf['goal_position'], test_set_kf['one_hot_goal'], traj_idx_kf = extract_data(pklfile, full_traj=True, crop_traj=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "history_shape = test_set['history_traj_data'].shape\n",
    "goals_position_shape = test_set['goal_position'].shape\n",
    "one_hot_goal_shape = test_set['one_hot_goal'].shape\n",
    "future_shape = test_set['future_traj_data'].shape\n",
    "hidden_dim = 100\n",
    "beta = 0.\n",
    "gamma = 10.\n",
    "use_goal_info = True\n",
    "comb_lstm = CombinedLSTM(history_shape, goals_position_shape, one_hot_goal_shape, future_shape, hidden_dim, beta, gamma, use_goal_info)\n",
    "# comb_lstm.load('file_name')\n",
    "# comb_lstm.goal_model.load()\n",
    "# comb_lstm.traj_model.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_lstm.fit(test_set, test_set,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_lstm.save('./model/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comb_lstm.load('./model/LSTM_h100_b1.000_fold0')\n",
    "comb_lstm.load('./model/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_goal = [0, 1, 2]\n",
    "goal_pred, traj_pred_dict = comb_lstm.predict(test_set, top_k_goal=top_k_goal)\n",
    "print(traj_pred_dict[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = EKF_CV_MODEL(x_init=np.zeros(5), P_init=np.eye(5), R=np.diag([1e-3]*3), dt=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf.load('./model/EKF_CV_fold0.pkl')\n",
    "goal_pred, traj_pred_dict = kf.predict(test_set_kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_plot('test_lstm', test_set, traj_idx, goal_pred, traj_pred_dict, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(traj_idx) - 1)\n",
    "\n",
    "# Plot the result\n",
    "goal_ind = np.arange(33)\n",
    "bar_width = 0.35\n",
    "# Recover the goal coordinates\n",
    "test_goals_coords = test_set['goal_position'].reshape((test_set['goal_position'].shape[0], 32, 3))\n",
    "test_hist_traj    = test_set['history_traj_data']\n",
    "test_future_traj  = test_set['future_traj_data']\n",
    "test_one_hot_goal = test_set['one_hot_goal']\n",
    "\n",
    "for num_traj in range(2):\n",
    "    \n",
    "    print(\"Start processing trajectory # %03d .....\" % num_traj)\n",
    "    start_idx = traj_idx[num_traj]\n",
    "    end_idx   = traj_idx[num_traj+1]\n",
    "    directory = './figures/%03d' % num_traj\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "\n",
    "    for i in range(start_idx, end_idx):\n",
    "\n",
    "        fig = plt.figure(dpi=200)\n",
    "        plt.suptitle('LSTM', va='center')\n",
    "        plt.subplot(211)\n",
    "\n",
    "        vector = test_goals_coords[i][-3,:2] - test_goals_coords[i][-1,:2]\n",
    "        th = np.arctan2(vector[1], vector[0])\n",
    "        R = np.array([[ np.cos(th), np.sin(th)], \\\n",
    "                      [-np.sin(th), np.cos(th)]])\n",
    "\n",
    "        # Plot the vehicle trajectory in the snippet\n",
    "        test_hist_traj_rot = test_hist_traj[i][:,:2] @ R.T\n",
    "        test_future_traj_rot = test_future_traj[i][:,:2] @ R.T\n",
    "        plt.plot(test_hist_traj_rot[:,0], test_hist_traj_rot[:,1], 'k')\n",
    "        plt.plot(test_future_traj_rot[:,0], test_future_traj_rot[:,1], color = '#1f77b4')\n",
    "        \n",
    "        probs = goal_pred[i].copy()\n",
    "        prob_undetermined = probs[-1]\n",
    "        probs.sort()\n",
    "        for top_k, traj_pred in traj_pred_dict.items():\n",
    "            traj_pred_rot      = traj_pred[i][:, :2] @ R.T\n",
    "            prob = probs[-1-top_k]\n",
    "            plt.plot(traj_pred_rot[:,0], traj_pred_rot[:,1], '.', markersize = 3, color = '#ff770e', alpha= prob)\n",
    "\n",
    "        # Plot the occupancy in the snippet\n",
    "        test_goals_coords_rot = test_goals_coords[i][:,:2] @ R.T\n",
    "        for goal, occup in zip(test_goals_coords_rot, test_goals_coords[i]):\n",
    "            if occup[2] > 0:\n",
    "                plt.plot(goal[0], goal[1], 'ko', fillstyle='none', markersize = 9)\n",
    "            else:\n",
    "                plt.plot(goal[0], goal[1], 'ko', markersize = 9)\n",
    "\n",
    "        # Get the ground truth intention\n",
    "        gt_idx = np.argmax(test_one_hot_goal[i])\n",
    "        # Predictions above a threshold\n",
    "        thres = 1e-2\n",
    "        \n",
    "        best_k_idx = [np.argsort(goal_pred[i])[-1-k] for k in top_k_goal]\n",
    "#         best_k_idx = [k for k, p in enumerate(goal_pred[i]) if p >= thres]\n",
    "#         print(np.max(goal_pred[i]))\n",
    "        if gt_idx == 32: # If it is \"-1\" -> undetermined \n",
    "            plt.plot(0, 0, 'v', fillstyle='bottom', color = '#1f77b4', markersize = 9)\n",
    "        else:\n",
    "            plt.plot(test_goals_coords_rot[gt_idx][0], test_goals_coords_rot[gt_idx][1], 'o', fillstyle='bottom', color = '#1f77b4', markersize = 9)\n",
    "\n",
    "        for j in best_k_idx:\n",
    "            if j == 32:\n",
    "                plt.plot(0, 0, 'v', fillstyle='none', color = '#ff770e', markersize = 9, alpha=prob_undetermined)\n",
    "            else:\n",
    "                plt.plot(test_goals_coords_rot[j][0], test_goals_coords_rot[j][1], 'o', fillstyle='none', color = '#ff770e', markersize = 9)\n",
    "\n",
    "        plt.title('Trajectory and Spots in Ego Frame')\n",
    "        plt.xlabel('x (m)')\n",
    "        plt.ylabel('y (m)')\n",
    "    #     plt.axis('equal')\n",
    "\n",
    "        plt.subplot(212)\n",
    "        p1 = plt.bar(goal_ind - bar_width/2, test_one_hot_goal[i], bar_width, label='GT')\n",
    "        p2 = plt.bar(goal_ind + bar_width/2, goal_pred[i], bar_width, label='Pred')\n",
    "        plt.xlabel('Goal Index')\n",
    "        plt.ylabel('Probability')\n",
    "        plt.title('Likelihood of Selecting Different Goals')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        \n",
    "        fig.savefig('./figures/%03d/frame_%03d.png' % (num_traj, i-start_idx))\n",
    "        plt.close(fig)\n",
    "        \n",
    "    fps = 2\n",
    "    mv = os.system(\"ffmpeg -r {0:d} -i ./figures/{1:03d}/frame_%03d.png -vcodec mpeg4 -y ./figures/{1:03d}_movie.mp4\".format(fps, num_traj) )\n",
    "    if mv == 0:\n",
    "        print(\"Trajectory # %03d movie saved successfully.\" % num_traj)\n",
    "    else:\n",
    "        print(\"Meet problem saving Trajectory # %03d movie.\" % num_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
